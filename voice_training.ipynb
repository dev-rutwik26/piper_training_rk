{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a370f40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import sounddevice as sd\n",
    "from piper.voice import PiperVoice\n",
    "import re\n",
    "import queue\n",
    "import time\n",
    "import threading\n",
    "import wave\n",
    "import numpy as np\n",
    "\n",
    "class Text_to_Speech:\n",
    "    def __init__(self):\n",
    "        #hi/hi_IN/pratham/medium\n",
    "        # self.PIPER_MODEL = \"./piper_model/hi_IN-priyamvada-medium.onnx\"\n",
    "        # self.PIPER_CONFIG = \"./piper_model/hi_IN-priyamvada-medium.json\"\n",
    "        self.PIPER_MODEL = \"scripts/exported_models/lj-med.onnx\"\n",
    "        self.PIPER_CONFIG = \"scripts/exported_models/lj-med.onnx.json\"\n",
    "        self.SAMPLE_RATE = 22050\n",
    "        self.OVERLAP = 0.15  # seconds of audio overlap for smooth playback\n",
    "        \n",
    "        # Check if model files exist, if not download them\n",
    "        if not os.path.exists(self.PIPER_MODEL) or not os.path.exists(self.PIPER_CONFIG):\n",
    "            print(\"‚ö†Ô∏è  Model files not found. Downloading...\")\n",
    "            # self.download_model()\n",
    "        \n",
    "        self.model = PiperVoice.load(model_path=self.PIPER_MODEL, config_path=self.PIPER_CONFIG)\n",
    "\n",
    "    # def download_model(self):\n",
    "    \n",
    "    #     os.makedirs(\"./piper_model\", exist_ok=True)\n",
    "\n",
    "    #     model_url = \"https://huggingface.co/rhasspy/piper-voices/resolve/main/hi/hi_IN/rohan/medium/hi_IN-rohan-medium.onnx?download=true\"\n",
    "    #     model_path = \"./piper_model/hi_IN-rohan-medium.onnx\"\n",
    "\n",
    "    #     print(\"üîΩ Downloading piper ONNX Quantized (60MB) model...\")\n",
    "    #     with requests.get(model_url, stream=True) as r:\n",
    "    #         r.raise_for_status()\n",
    "    #         with open(model_path, \"wb\") as f:\n",
    "    #             for chunk in r.iter_content(chunk_size=8192):\n",
    "    #                 f.write(chunk)\n",
    "    #     print(f\"‚úÖ Model saved to {model_path} ({os.path.getsize(model_path)//1_000_000} MB)\\n\")\n",
    "        \n",
    "    #     voice_url = \"https://huggingface.co/rhasspy/piper-voices/resolve/main/hi/hi_IN/rohan/medium/hi_IN-rohan-medium.onnx.json?download=true\"\n",
    "    #     voice_path = \"./piper_model/hi_IN-rohan-medium.json\"\n",
    "\n",
    "    #     print(\"üîΩ Downloading voice: piper config ...\")\n",
    "    #     with requests.get(voice_url, stream=True) as r:\n",
    "    #         r.raise_for_status()\n",
    "    #         with open(voice_path, \"wb\") as f:\n",
    "    #             for chunk in r.iter_content(chunk_size=8192):\n",
    "    #                 f.write(chunk)\n",
    "    #     print(f\"‚úÖ Voice saved to {voice_path} ({os.path.getsize(voice_path)//1_000_000} MB)\")\n",
    "    #     return \"Done\"\n",
    "\n",
    "    def synthesizer_worker(self,q_text: queue.Queue, q_audio: queue.Queue, logs: list, full_audio_buffer: list = None):\n",
    "        \"\"\"Continuously pulls text sentences, synthesizes them, and queues audio.\"\"\"\n",
    "        while True:\n",
    "            sentence = q_text.get()\n",
    "            if sentence is None:\n",
    "                print(\"[Synthesizer] Got None, stopping...\")\n",
    "                q_audio.put(None)\n",
    "                break\n",
    "\n",
    "            print(f\"[Synthesizer] Processing: '{sentence}'\")\n",
    "            synth_start = time.time()\n",
    "            audio_data = []\n",
    "            for chunk in self.model.synthesize(sentence):\n",
    "                audio_data.extend(chunk.audio_float_array)\n",
    "            synth_end = time.time()\n",
    "\n",
    "            synth_time = synth_end - synth_start\n",
    "            print(f\"[Synthesizer] Generated {len(audio_data)} samples in {synth_time:.3f}s\")\n",
    "            \n",
    "            logs.append({\n",
    "                \"type\": \"synthesis\",\n",
    "                \"text\": sentence,\n",
    "                \"duration_sec\": synth_time,\n",
    "                \"samples\": len(audio_data),\n",
    "            })\n",
    "\n",
    "            # Check for None explicitly to avoid issues in threads\n",
    "            if full_audio_buffer is not None:\n",
    "                full_audio_buffer.extend(audio_data)\n",
    "\n",
    "            q_audio.put(audio_data)\n",
    "\n",
    "    def player_worker(self,q_audio: queue.Queue, logs: list):\n",
    "        \"\"\"Continuously pulls audio chunks and plays them with soft overlap.\"\"\"\n",
    "        print(\"üéß Player thread started...\")\n",
    "\n",
    "        while True:\n",
    "            audio_chunk = q_audio.get()\n",
    "            if audio_chunk is None:\n",
    "                print(\"üõë Player thread stopping.\")\n",
    "                break\n",
    "            play_start = time.time()\n",
    "            sd.play(audio_chunk, samplerate=self.SAMPLE_RATE)\n",
    "            \n",
    "            # Wait for audio to complete playback\n",
    "            sd.wait()\n",
    "            play_end = time.time()\n",
    "\n",
    "            logs.append({\n",
    "                \"type\": \"playback\",\n",
    "                \"duration_sec\": play_end - play_start,\n",
    "                \"samples\": len(audio_chunk),\n",
    "            })\n",
    "\n",
    "    def save_wav(self, file_path, audio_data):\n",
    "        \"\"\"Saves audio data to a WAV file.\"\"\"\n",
    "        if not audio_data:\n",
    "            print(\"‚ö†Ô∏è No audio data to save.\")\n",
    "            return\n",
    "\n",
    "        print(f\"üíæ Saving audio to {file_path}...\")\n",
    "        try:\n",
    "            # Ensure directory exists\n",
    "            os.makedirs(os.path.dirname(os.path.abspath(file_path)), exist_ok=True)\n",
    "            \n",
    "            # Convert float list to numpy array\n",
    "            audio_np = np.array(audio_data, dtype=np.float32)\n",
    "            \n",
    "            # Convert to int16 PCM (scale -1.0 to 1.0 -> -32768 to 32767)\n",
    "            # Clip is important to avoid overflow wraparound\n",
    "            audio_int16 = (audio_np * 32767).clip(-32768, 32767).astype(np.int16)\n",
    "            \n",
    "            with wave.open(file_path, \"wb\") as wf:\n",
    "                wf.setnchannels(1)  # Mono\n",
    "                wf.setsampwidth(2)  # 2 bytes (16 bit)\n",
    "                wf.setframerate(self.SAMPLE_RATE)\n",
    "                wf.writeframes(audio_int16.tobytes())\n",
    "            \n",
    "            print(f\"‚úÖ Audio successfully saved to {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error saving WAV file: {e}\")\n",
    "\n",
    "    def text_to_speech_stream(self,text: str, output_wav: str = None):\n",
    "        \"\"\"\n",
    "        Takes a block of text, streams synthesis + playback with overlap.\n",
    "        Optionally saves the full session to a WAV file.\n",
    "        \"\"\"\n",
    "        print(\"üß© Starting Text ‚Üí Speech pipeline...\\n\")\n",
    "\n",
    "        q_text = queue.Queue(maxsize=5)\n",
    "        q_audio = queue.Queue(maxsize=5)\n",
    "        logs = []\n",
    "        full_audio_buffer = [] if output_wav else None\n",
    "\n",
    "        # Pass full_audio_buffer to synthesizer worker if we want to save\n",
    "        synth_thread = threading.Thread(target=self.synthesizer_worker, args=(q_text, q_audio, logs, full_audio_buffer))\n",
    "        play_thread = threading.Thread(target=self.player_worker, args=(q_audio, logs))\n",
    "\n",
    "        synth_thread.start()\n",
    "        play_thread.start()\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        sentences = re.split(r'(?<=[.!?]) +', text.strip())\n",
    "\n",
    "        for sentence in sentences:\n",
    "            if sentence.strip():\n",
    "                q_text.put(sentence.strip())\n",
    "\n",
    "        q_text.put(None)\n",
    "        synth_thread.join()\n",
    "        play_thread.join()\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(\"\\n‚úÖ Pipeline complete.\")\n",
    "        print(f\"‚è±Ô∏è Total runtime: {end_time - start_time:.2f}s\\n\")\n",
    "        \n",
    "        if output_wav and full_audio_buffer:\n",
    "            self.save_wav(output_wav, full_audio_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa9ca19",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "tts = Text_to_Speech()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48c9585d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "tts.text_to_speech_stream(\"My name is Priya and I work as a teacher in Mumbai. Every morning, I take the local train to reach my school. The weather here is very humid, especially during the monsoon season. After work, I often visit the market to buy vegetables and other groceries. My mother and father live nearby, so I visit them regularly on weekends.\",\"prove_4.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cfe1de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voice_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
