{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a370f40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import sounddevice as sd\n",
    "from piper.voice import PiperVoice\n",
    "import re\n",
    "import queue\n",
    "import time\n",
    "import threading\n",
    "import wave\n",
    "import numpy as np\n",
    "\n",
    "class Text_to_Speech:\n",
    "    def __init__(self):\n",
    "        #hi/hi_IN/pratham/medium\n",
    "        # self.PIPER_MODEL = \"./piper_model/hi_IN-priyamvada-medium.onnx\"\n",
    "        # self.PIPER_CONFIG = \"./piper_model/hi_IN-priyamvada-medium.json\"\n",
    "        self.PIPER_MODEL = \"scripts/exported_models/lj-med.onnx\"\n",
    "        self.PIPER_CONFIG = \"scripts/exported_models/lj-med.onnx.json\"\n",
    "        self.SAMPLE_RATE = 22050\n",
    "        self.OVERLAP = 0.15  # seconds of audio overlap for smooth playback\n",
    "        \n",
    "        # Check if model files exist, if not download them\n",
    "        if not os.path.exists(self.PIPER_MODEL) or not os.path.exists(self.PIPER_CONFIG):\n",
    "            print(\"‚ö†Ô∏è  Model files not found. Downloading...\")\n",
    "            # self.download_model()\n",
    "        \n",
    "        self.model = PiperVoice.load(model_path=self.PIPER_MODEL, config_path=self.PIPER_CONFIG)\n",
    "\n",
    "    # def download_model(self):\n",
    "    \n",
    "    #     os.makedirs(\"./piper_model\", exist_ok=True)\n",
    "\n",
    "    #     model_url = \"https://huggingface.co/rhasspy/piper-voices/resolve/main/hi/hi_IN/rohan/medium/hi_IN-rohan-medium.onnx?download=true\"\n",
    "    #     model_path = \"./piper_model/hi_IN-rohan-medium.onnx\"\n",
    "\n",
    "    #     print(\"üîΩ Downloading piper ONNX Quantized (60MB) model...\")\n",
    "    #     with requests.get(model_url, stream=True) as r:\n",
    "    #         r.raise_for_status()\n",
    "    #         with open(model_path, \"wb\") as f:\n",
    "    #             for chunk in r.iter_content(chunk_size=8192):\n",
    "    #                 f.write(chunk)\n",
    "    #     print(f\"‚úÖ Model saved to {model_path} ({os.path.getsize(model_path)//1_000_000} MB)\\n\")\n",
    "        \n",
    "    #     voice_url = \"https://huggingface.co/rhasspy/piper-voices/resolve/main/hi/hi_IN/rohan/medium/hi_IN-rohan-medium.onnx.json?download=true\"\n",
    "    #     voice_path = \"./piper_model/hi_IN-rohan-medium.json\"\n",
    "\n",
    "    #     print(\"üîΩ Downloading voice: piper config ...\")\n",
    "    #     with requests.get(voice_url, stream=True) as r:\n",
    "    #         r.raise_for_status()\n",
    "    #         with open(voice_path, \"wb\") as f:\n",
    "    #             for chunk in r.iter_content(chunk_size=8192):\n",
    "    #                 f.write(chunk)\n",
    "    #     print(f\"‚úÖ Voice saved to {voice_path} ({os.path.getsize(voice_path)//1_000_000} MB)\")\n",
    "    #     return \"Done\"\n",
    "\n",
    "    def synthesizer_worker(self,q_text: queue.Queue, q_audio: queue.Queue, logs: list, full_audio_buffer: list = None):\n",
    "        \"\"\"Continuously pulls text sentences, synthesizes them, and queues audio.\"\"\"\n",
    "        while True:\n",
    "            sentence = q_text.get()\n",
    "            if sentence is None:\n",
    "                print(\"[Synthesizer] Got None, stopping...\")\n",
    "                q_audio.put(None)\n",
    "                break\n",
    "\n",
    "            print(f\"[Synthesizer] Processing: '{sentence}'\")\n",
    "            synth_start = time.time()\n",
    "            audio_data = []\n",
    "            for chunk in self.model.synthesize(sentence):\n",
    "                audio_data.extend(chunk.audio_float_array)\n",
    "            synth_end = time.time()\n",
    "\n",
    "            synth_time = synth_end - synth_start\n",
    "            print(f\"[Synthesizer] Generated {len(audio_data)} samples in {synth_time:.3f}s\")\n",
    "            \n",
    "            logs.append({\n",
    "                \"type\": \"synthesis\",\n",
    "                \"text\": sentence,\n",
    "                \"duration_sec\": synth_time,\n",
    "                \"samples\": len(audio_data),\n",
    "            })\n",
    "\n",
    "            # Check for None explicitly to avoid issues in threads\n",
    "            if full_audio_buffer is not None:\n",
    "                full_audio_buffer.extend(audio_data)\n",
    "\n",
    "            q_audio.put(audio_data)\n",
    "\n",
    "    def player_worker(self,q_audio: queue.Queue, logs: list):\n",
    "        \"\"\"Continuously pulls audio chunks and plays them with soft overlap.\"\"\"\n",
    "        print(\"üéß Player thread started...\")\n",
    "\n",
    "        while True:\n",
    "            audio_chunk = q_audio.get()\n",
    "            if audio_chunk is None:\n",
    "                print(\"üõë Player thread stopping.\")\n",
    "                break\n",
    "            play_start = time.time()\n",
    "            sd.play(audio_chunk, samplerate=self.SAMPLE_RATE)\n",
    "            \n",
    "            # Wait for audio to complete playback\n",
    "            sd.wait()\n",
    "            play_end = time.time()\n",
    "\n",
    "            logs.append({\n",
    "                \"type\": \"playback\",\n",
    "                \"duration_sec\": play_end - play_start,\n",
    "                \"samples\": len(audio_chunk),\n",
    "            })\n",
    "\n",
    "    def save_wav(self, file_path, audio_data):\n",
    "        \"\"\"Saves audio data to a WAV file.\"\"\"\n",
    "        if not audio_data:\n",
    "            print(\"‚ö†Ô∏è No audio data to save.\")\n",
    "            return\n",
    "\n",
    "        print(f\"üíæ Saving audio to {file_path}...\")\n",
    "        try:\n",
    "            # Ensure directory exists\n",
    "            os.makedirs(os.path.dirname(os.path.abspath(file_path)), exist_ok=True)\n",
    "            \n",
    "            # Convert float list to numpy array\n",
    "            audio_np = np.array(audio_data, dtype=np.float32)\n",
    "            \n",
    "            # Convert to int16 PCM (scale -1.0 to 1.0 -> -32768 to 32767)\n",
    "            # Clip is important to avoid overflow wraparound\n",
    "            audio_int16 = (audio_np * 32767).clip(-32768, 32767).astype(np.int16)\n",
    "            \n",
    "            with wave.open(file_path, \"wb\") as wf:\n",
    "                wf.setnchannels(1)  # Mono\n",
    "                wf.setsampwidth(2)  # 2 bytes (16 bit)\n",
    "                wf.setframerate(self.SAMPLE_RATE)\n",
    "                wf.writeframes(audio_int16.tobytes())\n",
    "            \n",
    "            print(f\"‚úÖ Audio successfully saved to {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error saving WAV file: {e}\")\n",
    "\n",
    "    def text_to_speech_stream(self,text: str, output_wav: str = None):\n",
    "        \"\"\"\n",
    "        Takes a block of text, streams synthesis + playback with overlap.\n",
    "        Optionally saves the full session to a WAV file.\n",
    "        \"\"\"\n",
    "        print(\"üß© Starting Text ‚Üí Speech pipeline...\\n\")\n",
    "\n",
    "        q_text = queue.Queue(maxsize=5)\n",
    "        q_audio = queue.Queue(maxsize=5)\n",
    "        logs = []\n",
    "        full_audio_buffer = [] if output_wav else None\n",
    "\n",
    "        # Pass full_audio_buffer to synthesizer worker if we want to save\n",
    "        synth_thread = threading.Thread(target=self.synthesizer_worker, args=(q_text, q_audio, logs, full_audio_buffer))\n",
    "        play_thread = threading.Thread(target=self.player_worker, args=(q_audio, logs))\n",
    "\n",
    "        synth_thread.start()\n",
    "        play_thread.start()\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        sentences = re.split(r'(?<=[.!?]) +', text.strip())\n",
    "\n",
    "        for sentence in sentences:\n",
    "            if sentence.strip():\n",
    "                q_text.put(sentence.strip())\n",
    "\n",
    "        q_text.put(None)\n",
    "        synth_thread.join()\n",
    "        play_thread.join()\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(\"\\n‚úÖ Pipeline complete.\")\n",
    "        print(f\"‚è±Ô∏è Total runtime: {end_time - start_time:.2f}s\\n\")\n",
    "        \n",
    "        if output_wav and full_audio_buffer:\n",
    "            self.save_wav(output_wav, full_audio_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fa9ca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "tts = Text_to_Speech()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48c9585d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß© Starting Text ‚Üí Speech pipeline...\n",
      "\n",
      "üéß Player thread started...\n",
      "[Synthesizer] Processing: 'My name is Priya and I work as a teacher in Mumbai.'\n",
      "[Synthesizer] Generated 69632 samples in 0.450s\n",
      "[Synthesizer] Processing: 'Every morning, I take the local train to reach my school.'\n",
      "[Synthesizer] Generated 59136 samples in 0.305s\n",
      "[Synthesizer] Processing: 'The weather here is very humid, especially during the monsoon season.'\n",
      "[Synthesizer] Generated 93184 samples in 0.434s\n",
      "[Synthesizer] Processing: 'After work, I often visit the market to buy vegetables and other groceries.'\n",
      "[Synthesizer] Generated 115712 samples in 0.554s\n",
      "[Synthesizer] Processing: 'My mother and father live nearby, so I visit them regularly on weekends.'\n",
      "[Synthesizer] Generated 89600 samples in 0.419s\n",
      "[Synthesizer] Got None, stopping...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtts\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext_to_speech_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMy name is Priya and I work as a teacher in Mumbai. Every morning, I take the local train to reach my school. The weather here is very humid, especially during the monsoon season. After work, I often visit the market to buy vegetables and other groceries. My mother and father live nearby, so I visit them regularly on weekends.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprove_4.wav\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 167\u001b[39m, in \u001b[36mText_to_Speech.text_to_speech_stream\u001b[39m\u001b[34m(self, text, output_wav)\u001b[39m\n\u001b[32m    165\u001b[39m q_text.put(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    166\u001b[39m synth_thread.join()\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m \u001b[43mplay_thread\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    169\u001b[39m end_time = time.time()\n\u001b[32m    170\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m‚úÖ Pipeline complete.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/voice_training/lib/python3.11/threading.py:1119\u001b[39m, in \u001b[36mThread.join\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1116\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot join current thread\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1119\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1120\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1121\u001b[39m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[32m   1122\u001b[39m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[32m   1123\u001b[39m     \u001b[38;5;28mself\u001b[39m._wait_for_tstate_lock(timeout=\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[32m0\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/voice_training/lib/python3.11/threading.py:1139\u001b[39m, in \u001b[36mThread._wait_for_tstate_lock\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m   1136\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1138\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1139\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1140\u001b[39m         lock.release()\n\u001b[32m   1141\u001b[39m         \u001b[38;5;28mself\u001b[39m._stop()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "tts.text_to_speech_stream(\"My name is Priya and I work as a teacher in Mumbai. Every morning, I take the local train to reach my school. The weather here is very humid, especially during the monsoon season. After work, I often visit the market to buy vegetables and other groceries. My mother and father live nearby, so I visit them regularly on weekends.\",\"prove_4.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cfe1de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voice_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
