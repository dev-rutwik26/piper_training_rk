{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5237c738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import sounddevice as sd\n",
    "from piper.voice import PiperVoice\n",
    "import re\n",
    "import queue\n",
    "import time\n",
    "import threading\n",
    "\n",
    "class Text_to_Speech:\n",
    "    def __init__(self):\n",
    "        self.PIPER_MODEL = \"./piper_model/hi_IN-priyamvada-medium.onnx\"\n",
    "        self.PIPER_CONFIG = \"./piper_model/hi_IN-priyamvada-medium.json\"\n",
    "        self.SAMPLE_RATE = 22050\n",
    "        self.OVERLAP = 0.15  # seconds of audio overlap for smooth playback\n",
    "        \n",
    "        # Check if model files exist, if not download them\n",
    "        if not os.path.exists(self.PIPER_MODEL) or not os.path.exists(self.PIPER_CONFIG):\n",
    "            print(\"‚ö†Ô∏è  Model files not found. Downloading...\")\n",
    "            self.download_model()\n",
    "        \n",
    "        self.model = PiperVoice.load(model_path=self.PIPER_MODEL, config_path=self.PIPER_CONFIG)\n",
    "\n",
    "    def download_model(self):\n",
    "    \n",
    "        os.makedirs(\"./piper_model\", exist_ok=True)\n",
    "\n",
    "        # model_url = \"https://huggingface.co/rhasspy/piper-voices/resolve/main/en/en_US/amy/medium/en_US-amy-medium.onnx?download=true\"\n",
    "        # model_path = \"./piper_model/en_US-hfc_female-medium.onnx\"\n",
    "\n",
    "        model_url = \"https://huggingface.co/rhasspy/piper-voices/resolve/main/hi/hi_IN/priyamvada/medium/hi_IN-priyamvada-medium.onnx?download=true\"\n",
    "#https://huggingface.co/rhasspy/piper-voices/resolve/main/hi/hi_IN/pratham/medium/hi_IN-pratham-medium.onnx?download=true\n",
    "        model_path = \"./piper_model/hi_IN-priyamvada-medium.onnx\"\n",
    "\n",
    "        print(\"üîΩ Downloading piper ONNX Quantized (60MB) model...\")\n",
    "        with requests.get(model_url, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "            with open(model_path, \"wb\") as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "        print(f\"‚úÖ Model saved to {model_path} ({os.path.getsize(model_path)//1_000_000} MB)\\n\")\n",
    "\n",
    "        voice_url = \"https://huggingface.co/rhasspy/piper-voices/resolve/main/hi/hi_IN/priyamvada/medium/hi_IN-priyamvada-medium.onnx.json?download=true\"\n",
    "#https://huggingface.co/rhasspy/piper-voices/resolve/main/hi/hi_IN/pratham/medium/hi_IN-pratham-medium.onnx.json?download=true\n",
    "        voice_path = \"./piper_model/hi_IN-priyamvada-medium.json\"\n",
    "\n",
    "        print(\"üîΩ Downloading voice: piper config ...\")\n",
    "        with requests.get(voice_url, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "            with open(voice_path, \"wb\") as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "        print(f\"‚úÖ Voice saved to {voice_path} ({os.path.getsize(voice_path)//1_000_000} MB)\")\n",
    "        return \"Done\"\n",
    "\n",
    "    def synthesizer_worker(self,q_text: queue.Queue, q_audio: queue.Queue, logs: list):\n",
    "        \"\"\"Continuously pulls text sentences, synthesizes them, and queues audio.\"\"\"\n",
    "        while True:\n",
    "            sentence = q_text.get()\n",
    "            if sentence is None:\n",
    "                print(\"[Synthesizer] Got None, stopping...\")\n",
    "                q_audio.put(None)\n",
    "                break\n",
    "\n",
    "            print(f\"[Synthesizer] Processing: '{sentence}'\")\n",
    "            synth_start = time.time()\n",
    "            audio_data = []\n",
    "            for chunk in self.model.synthesize(sentence):\n",
    "                audio_data.extend(chunk.audio_float_array)\n",
    "            synth_end = time.time()\n",
    "\n",
    "            synth_time = synth_end - synth_start\n",
    "            print(f\"[Synthesizer] Generated {len(audio_data)} samples in {synth_time:.3f}s\")\n",
    "            \n",
    "            logs.append({\n",
    "                \"type\": \"synthesis\",\n",
    "                \"text\": sentence,\n",
    "                \"duration_sec\": synth_time,\n",
    "                \"samples\": len(audio_data),\n",
    "            })\n",
    "\n",
    "            q_audio.put(audio_data)\n",
    "\n",
    "    def player_worker(self,q_audio: queue.Queue, logs: list):\n",
    "        \"\"\"Continuously pulls audio chunks and plays them with soft overlap.\"\"\"\n",
    "        print(\"üéß Player thread started...\")\n",
    "\n",
    "        while True:\n",
    "            audio_chunk = q_audio.get()\n",
    "            if audio_chunk is None:\n",
    "                print(\"üõë Player thread stopping.\")\n",
    "                break\n",
    "            play_start = time.time()\n",
    "            sd.play(audio_chunk, samplerate=self.SAMPLE_RATE)\n",
    "            \n",
    "            # Wait for audio to complete playback\n",
    "            sd.wait()\n",
    "            play_end = time.time()\n",
    "\n",
    "            logs.append({\n",
    "                \"type\": \"playback\",\n",
    "                \"duration_sec\": play_end - play_start,\n",
    "                \"samples\": len(audio_chunk),\n",
    "            })\n",
    "\n",
    "    def text_to_speech_stream(self,text: str):\n",
    "        \"\"\"\n",
    "        Takes a block of text, splits it into sentences,\n",
    "        and streams synthesis + playback with overlap.\n",
    "        \"\"\"\n",
    "        print(\"üß© Starting Text ‚Üí Speech pipeline...\\n\")\n",
    "\n",
    "        q_text = queue.Queue(maxsize=5)\n",
    "        q_audio = queue.Queue(maxsize=5)\n",
    "        logs = []\n",
    "\n",
    "        synth_thread = threading.Thread(target=self.synthesizer_worker, args=(q_text, q_audio, logs))\n",
    "        play_thread = threading.Thread(target=self.player_worker, args=(q_audio, logs))\n",
    "\n",
    "        synth_thread.start()\n",
    "        play_thread.start()\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        sentences = re.split(r'(?<=[.!?]) +', text.strip())\n",
    "\n",
    "        for sentence in sentences:\n",
    "            if sentence.strip():\n",
    "                q_text.put(sentence.strip())\n",
    "\n",
    "        q_text.put(None)\n",
    "\n",
    "        synth_thread.join()\n",
    "        play_thread.join()\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(\"\\n‚úÖ Pipeline complete.\")\n",
    "        print(f\"‚è±Ô∏è Total runtime: {end_time - start_time:.2f}s\\n\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54d2b319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Model files not found. Downloading...\n",
      "üîΩ Downloading piper ONNX Quantized (60MB) model...\n",
      "‚úÖ Model saved to ./piper_model/hi_IN-priyamvada-medium.onnx (63 MB)\n",
      "\n",
      "üîΩ Downloading voice: piper config ...\n",
      "‚úÖ Voice saved to ./piper_model/hi_IN-priyamvada-medium.json (0 MB)\n"
     ]
    }
   ],
   "source": [
    "text_class = Text_to_Speech()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5625f28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Text-to-Speech initialized successfully!\n",
      "üß© Starting Text ‚Üí Speech pipeline...\n",
      "\n",
      "üéß Player thread started...\n",
      "[Synthesizer] Processing: 'Hey Rutwik, can you tell us about yourself'\n",
      "[Synthesizer] Generated 68352 samples in 0.173s\n",
      "[Synthesizer] Got None, stopping...\n",
      "üõë Player thread stopping.\n",
      "\n",
      "‚úÖ Pipeline complete.\n",
      "‚è±Ô∏è Total runtime: 3.44s\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Hey Rutwik, can you tell us about yourself\"\"\"\n",
    "print(\"‚úÖ Text-to-Speech initialized successfully!\")\n",
    "text_class.text_to_speech_stream(text)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a370f40e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voice_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
