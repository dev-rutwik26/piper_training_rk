{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a370f40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import sounddevice as sd\n",
    "from piper.voice import PiperVoice\n",
    "import re\n",
    "import queue\n",
    "import time\n",
    "import threading\n",
    "import wave\n",
    "import numpy as np\n",
    "\n",
    "class Text_to_Speech:\n",
    "    def __init__(self):\n",
    "        #hi/hi_IN/pratham/medium\n",
    "        # self.PIPER_MODEL = \"./piper_model/hi_IN-priyamvada-medium.onnx\"\n",
    "        # self.PIPER_CONFIG = \"./piper_model/hi_IN-priyamvada-medium.json\"\n",
    "        self.PIPER_MODEL = \"scripts/exported_models/epoch=12640-step=44248.onnx\"\n",
    "        self.PIPER_CONFIG = \"scripts/exported_models/epoch=12640-step=44248.onnx.json\"\n",
    "        self.SAMPLE_RATE = 22050\n",
    "        self.OVERLAP = 0.15  # seconds of audio overlap for smooth playback\n",
    "        \n",
    "        # Check if model files exist, if not download them\n",
    "        if not os.path.exists(self.PIPER_MODEL) or not os.path.exists(self.PIPER_CONFIG):\n",
    "            print(\"‚ö†Ô∏è  Model files not found. Downloading...\")\n",
    "            # self.download_model()\n",
    "        \n",
    "        self.model = PiperVoice.load(model_path=self.PIPER_MODEL, config_path=self.PIPER_CONFIG)\n",
    "\n",
    "    # def download_model(self):\n",
    "    \n",
    "    #     os.makedirs(\"./piper_model\", exist_ok=True)\n",
    "\n",
    "    #     model_url = \"https://huggingface.co/rhasspy/piper-voices/resolve/main/hi/hi_IN/rohan/medium/hi_IN-rohan-medium.onnx?download=true\"\n",
    "    #     model_path = \"./piper_model/hi_IN-rohan-medium.onnx\"\n",
    "\n",
    "    #     print(\"üîΩ Downloading piper ONNX Quantized (60MB) model...\")\n",
    "    #     with requests.get(model_url, stream=True) as r:\n",
    "    #         r.raise_for_status()\n",
    "    #         with open(model_path, \"wb\") as f:\n",
    "    #             for chunk in r.iter_content(chunk_size=8192):\n",
    "    #                 f.write(chunk)\n",
    "    #     print(f\"‚úÖ Model saved to {model_path} ({os.path.getsize(model_path)//1_000_000} MB)\\n\")\n",
    "        \n",
    "    #     voice_url = \"https://huggingface.co/rhasspy/piper-voices/resolve/main/hi/hi_IN/rohan/medium/hi_IN-rohan-medium.onnx.json?download=true\"\n",
    "    #     voice_path = \"./piper_model/hi_IN-rohan-medium.json\"\n",
    "\n",
    "    #     print(\"üîΩ Downloading voice: piper config ...\")\n",
    "    #     with requests.get(voice_url, stream=True) as r:\n",
    "    #         r.raise_for_status()\n",
    "    #         with open(voice_path, \"wb\") as f:\n",
    "    #             for chunk in r.iter_content(chunk_size=8192):\n",
    "    #                 f.write(chunk)\n",
    "    #     print(f\"‚úÖ Voice saved to {voice_path} ({os.path.getsize(voice_path)//1_000_000} MB)\")\n",
    "    #     return \"Done\"\n",
    "\n",
    "    def synthesizer_worker(self,q_text: queue.Queue, q_audio: queue.Queue, logs: list, full_audio_buffer: list = None):\n",
    "        \"\"\"Continuously pulls text sentences, synthesizes them, and queues audio.\"\"\"\n",
    "        while True:\n",
    "            sentence = q_text.get()\n",
    "            if sentence is None:\n",
    "                print(\"[Synthesizer] Got None, stopping...\")\n",
    "                q_audio.put(None)\n",
    "                break\n",
    "\n",
    "            print(f\"[Synthesizer] Processing: '{sentence}'\")\n",
    "            synth_start = time.time()\n",
    "            audio_data = []\n",
    "            for chunk in self.model.synthesize(sentence):\n",
    "                audio_data.extend(chunk.audio_float_array)\n",
    "            synth_end = time.time()\n",
    "\n",
    "            synth_time = synth_end - synth_start\n",
    "            print(f\"[Synthesizer] Generated {len(audio_data)} samples in {synth_time:.3f}s\")\n",
    "            \n",
    "            logs.append({\n",
    "                \"type\": \"synthesis\",\n",
    "                \"text\": sentence,\n",
    "                \"duration_sec\": synth_time,\n",
    "                \"samples\": len(audio_data),\n",
    "            })\n",
    "\n",
    "            # Check for None explicitly to avoid issues in threads\n",
    "            if full_audio_buffer is not None:\n",
    "                full_audio_buffer.extend(audio_data)\n",
    "\n",
    "            q_audio.put(audio_data)\n",
    "\n",
    "    def player_worker(self,q_audio: queue.Queue, logs: list):\n",
    "        \"\"\"Continuously pulls audio chunks and plays them with soft overlap.\"\"\"\n",
    "        print(\"üéß Player thread started...\")\n",
    "\n",
    "        while True:\n",
    "            audio_chunk = q_audio.get()\n",
    "            if audio_chunk is None:\n",
    "                print(\"üõë Player thread stopping.\")\n",
    "                break\n",
    "            play_start = time.time()\n",
    "            sd.play(audio_chunk, samplerate=self.SAMPLE_RATE)\n",
    "            \n",
    "            # Wait for audio to complete playback\n",
    "            sd.wait()\n",
    "            play_end = time.time()\n",
    "\n",
    "            logs.append({\n",
    "                \"type\": \"playback\",\n",
    "                \"duration_sec\": play_end - play_start,\n",
    "                \"samples\": len(audio_chunk),\n",
    "            })\n",
    "\n",
    "    def save_wav(self, file_path, audio_data):\n",
    "        \"\"\"Saves audio data to a WAV file.\"\"\"\n",
    "        if not audio_data:\n",
    "            print(\"‚ö†Ô∏è No audio data to save.\")\n",
    "            return\n",
    "\n",
    "        print(f\"üíæ Saving audio to {file_path}...\")\n",
    "        try:\n",
    "            # Ensure directory exists\n",
    "            os.makedirs(os.path.dirname(os.path.abspath(file_path)), exist_ok=True)\n",
    "            \n",
    "            # Convert float list to numpy array\n",
    "            audio_np = np.array(audio_data, dtype=np.float32)\n",
    "            \n",
    "            # Convert to int16 PCM (scale -1.0 to 1.0 -> -32768 to 32767)\n",
    "            # Clip is important to avoid overflow wraparound\n",
    "            audio_int16 = (audio_np * 32767).clip(-32768, 32767).astype(np.int16)\n",
    "            \n",
    "            with wave.open(file_path, \"wb\") as wf:\n",
    "                wf.setnchannels(1)  # Mono\n",
    "                wf.setsampwidth(2)  # 2 bytes (16 bit)\n",
    "                wf.setframerate(self.SAMPLE_RATE)\n",
    "                wf.writeframes(audio_int16.tobytes())\n",
    "            \n",
    "            print(f\"‚úÖ Audio successfully saved to {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error saving WAV file: {e}\")\n",
    "\n",
    "    def text_to_speech_stream(self,text: str, output_wav: str = None):\n",
    "        \"\"\"\n",
    "        Takes a block of text, streams synthesis + playback with overlap.\n",
    "        Optionally saves the full session to a WAV file.\n",
    "        \"\"\"\n",
    "        print(\"üß© Starting Text ‚Üí Speech pipeline...\\n\")\n",
    "\n",
    "        q_text = queue.Queue(maxsize=5)\n",
    "        q_audio = queue.Queue(maxsize=5)\n",
    "        logs = []\n",
    "        full_audio_buffer = [] if output_wav else None\n",
    "\n",
    "        # Pass full_audio_buffer to synthesizer worker if we want to save\n",
    "        synth_thread = threading.Thread(target=self.synthesizer_worker, args=(q_text, q_audio, logs, full_audio_buffer))\n",
    "        play_thread = threading.Thread(target=self.player_worker, args=(q_audio, logs))\n",
    "\n",
    "        synth_thread.start()\n",
    "        play_thread.start()\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        sentences = re.split(r'(?<=[.!?]) +', text.strip())\n",
    "\n",
    "        for sentence in sentences:\n",
    "            if sentence.strip():\n",
    "                q_text.put(sentence.strip())\n",
    "\n",
    "        q_text.put(None)\n",
    "\n",
    "        synth_thread.join()\n",
    "        play_thread.join()\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(\"\\n‚úÖ Pipeline complete.\")\n",
    "        print(f\"‚è±Ô∏è Total runtime: {end_time - start_time:.2f}s\\n\")\n",
    "        \n",
    "        if output_wav and full_audio_buffer:\n",
    "            self.save_wav(output_wav, full_audio_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fa9ca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "tts = Text_to_Speech()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48c9585d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß© Starting Text ‚Üí Speech pipeline...\n",
      "\n",
      "üéß Player thread started...\n",
      "[Synthesizer] Processing: 'Hello world, this is a test of the exported Piper model.'\n",
      "[Synthesizer] Generated 404480 samples in 1.381s\n",
      "[Synthesizer] Got None, stopping...\n",
      "üõë Player thread stopping.\n",
      "\n",
      "‚úÖ Pipeline complete.\n",
      "‚è±Ô∏è Total runtime: 19.94s\n",
      "\n",
      "üíæ Saving audio to wav1.wav...\n",
      "‚úÖ Audio successfully saved to wav1.wav\n"
     ]
    }
   ],
   "source": [
    "tts.text_to_speech_stream(\"Hello world, this is a test of the exported Piper model.\",\"wav1.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2639f7c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voice_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
