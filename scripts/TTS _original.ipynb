{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UPN9ss5mOaY0"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "#import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "0jByCMSxYeks",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "a85b889d-c59b-47e0-ff55-92cd58f17407"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u4rmSFBzfOnf",
    "outputId": "e20e0617-74dd-49e9-a4ce-87eaf08b6037"
   },
   "outputs": [],
   "source": [
    "!unzip 'Hindi_TTS/hindi_male_mono.zip' -d dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!unzip 'Hindi_TTS/Hindi_male_mono_1.zip' -d dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nd3llLmSgUSc",
    "outputId": "027c9ffb-5300-4c0d-e0d5-880123dd2251",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!unzip 'dataset/IndicTTS_Phase2_Hindi_male_Speaker1_mono.zip' -d dataset/input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mv dataset/input/Hindi_male_mono/Hindi_male_audio/* dataset/input/mono/Read_speech/wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B7HvzMx2YX9_"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for root, dirs, files in os.walk('/content/drive/MyDrive/hindi_male_mono.zip'):\n",
    "    for file in files:\n",
    "        print(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "bKwYT_ZgYYcV"
   },
   "outputs": [],
   "source": [
    "path_to_file = 'dataset/input/mono/Read_speech/txt.done.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "UFu7680EYYkd"
   },
   "outputs": [],
   "source": [
    "text = open(path_to_file, 'r',encoding='utf-8',\n",
    "                 errors='ignore').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EwiIy8uAg5uW",
    "outputId": "08a878ad-b45c-431d-992f-2b9a7515533c"
   },
   "outputs": [],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qXwFnClVg9Tc",
    "outputId": "98761e2b-42cd-4a64-8143-49e3797beab1"
   },
   "outputs": [],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print(vocab)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0DqbY2zdhCEn",
    "outputId": "d00cd80a-bd91-4e46-bb88-e6379d9a6bbb"
   },
   "outputs": [],
   "source": [
    "char_to_ind = {u:i for i, u in enumerate(vocab)}\n",
    "ind_to_char = np.array(vocab)\n",
    "encoded_text = np.array([char_to_ind[c] for c in text])\n",
    "seq_len = 250\n",
    "total_num_seq = len(text)//(seq_len+1)\n",
    "total_num_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EE41QOwihHeS"
   },
   "outputs": [],
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)\n",
    "\n",
    "sequences = char_dataset.batch(seq_len+1, drop_remainder=True)\n",
    "\n",
    "def create_seq_targets(seq):\n",
    "    input_txt = seq[:-1]\n",
    "    target_txt = seq[1:]\n",
    "    return input_txt, target_txt\n",
    "\n",
    "dataset = sequences.map(create_seq_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "buffer_size =  10000\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_)size, drop_remainder=True)\n",
    "vocab_size = len(vocab)\n",
    "embed_dim = 64\n",
    "rnn_neurons = 2052"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "lJ-boV7ZM9sm",
    "outputId": "7d4aa624-3460-4660-ea9d-aedacc0b5671"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.copytree('/content/input_data/mono/Read_speech/wav', '/content/input/wavs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "h5BgyakeNkRI",
    "outputId": "ad744268-d771-4188-c418-22824adac749"
   },
   "outputs": [],
   "source": [
    "# Load and clean\n",
    "metadata_male_fp = \"dataset/input/mono/Read_speech/txt.done.data\"\n",
    "\n",
    "# Read file split by double quotes (to separate filename and transcript)\n",
    "metadata_male = pd.read_csv(metadata_male_fp, sep='\"', usecols=[0, 1], header=None)\n",
    "\n",
    "# Clean filename: remove leading '(' and whitespace\n",
    "metadata_male[0] = metadata_male[0].str.replace(r'\\(', '', regex=True).str.strip()\n",
    "\n",
    "# Clean transcript: remove leading/trailing whitespace\n",
    "metadata_male[1] = metadata_male[1].str.strip()\n",
    "\n",
    "# Optional: add speaker info\n",
    "metadata_male[2] = 'male'\n",
    "\n",
    "# Show shape and preview\n",
    "print(metadata_male.shape)\n",
    "metadata_male.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "pfBupyWZORfp"
   },
   "outputs": [],
   "source": [
    "metadata = metadata_male\n",
    "metadata.to_csv('dataset/input/mono/Read_speech/metadata.csv', sep='|', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xxTXpmmZS2S4",
    "outputId": "5b9923e9-6a8f-47ff-ee6c-8e1a4f343260"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'piper'...\n",
      "fatal: unable to access 'https://github.com/rhasspy/piper.git/': Could not resolve host: github.com\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Clone Piper repository (if not already)\n",
    "!git clone https://github.com/rhasspy/piper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7k1cmMR1aOsC",
    "outputId": "59004e0f-f6fe-4709-dc01-adedef3e3094"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://odpd.sac.gov.in/offline-pypi-mirror/simple/\n",
      "Collecting phonemizer\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/b6/23/e8d67c2052e132181c4c9027c2d8ed9e37e8acb27acfc13ed2d0c41ed850/phonemizer-3.3.0-py3-none-any.whl (103 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.8/103.8 kB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting Unidecode\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/8f/b7/559f59d57d18b44c6d1250d2eeaa676e028b9c527431f5d0736478a73ba1/Unidecode-1.4.0-py3-none-any.whl (235 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m160.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting librosa\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/b5/ba/c63c5786dfee4c3417094c4b00966e61e4a63efecee22cb7b4c0387dda83/librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.7/260.7 kB\u001b[0m \u001b[31m150.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in ./miniconda3/lib/python3.10/site-packages (4.65.0)\n",
      "Collecting inflect\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/8a/eb/427ed2b20a38a4ee29f24dbe4ae2dafab198674fe9a85e3d6adf9e5f5f41/inflect-7.5.0-py3-none-any.whl (35 kB)\n",
      "Collecting onnx\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/dd/5b/c4f95dbe652d14aeba9afaceb177e9ffc48ac3c03048dd3f872f26f07e34/onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m208.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting onnxruntime\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/a9/fb/76597b77785b2012317ffdd817101ccfab784e2c125645d002c4c9cd377b/onnxruntime-1.21.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m198.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting piper_phonemize\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/e9/e0/17c224e4a2a78c7fdd7c0a680693b1753293384ddfe860550950ed9b7e97/piper_phonemize-1.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (25.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.0/25.0 MB\u001b[0m \u001b[31m157.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in ./miniconda3/lib/python3.10/site-packages (from phonemizer) (4.13.2)\n",
      "Collecting segments\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/11/18/cb614939ccd46d336013cab705f1e11540ec9c68b08ecbb854ab893fc480/segments-2.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting dlinfo\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/da/90/022c79d6e5e6f843268c10b84d4a021ee3afba0621d3c176d3ff2024bfc8/dlinfo-2.0.0-py3-none-any.whl (3.7 kB)\n",
      "Collecting joblib\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/da/d3/13ee227a148af1c693654932b8b0b02ed64af5e1f7406d56b088b57574cd/joblib-1.5.0-py3-none-any.whl (307 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m190.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=18.1 in ./miniconda3/lib/python3.10/site-packages (from phonemizer) (25.3.0)\n",
      "Collecting numba>=0.51.0\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/e2/7d/bfb2805bcfbd479f04f835241ecf28519f6e3609912e3a985aed45e21370/numba-0.61.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m234.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting audioread>=2.1.9\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/57/8d/30aa32745af16af0a9a650115fbe81bde7c610ed5c21b381fca0196f3a7f/audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Collecting pooch>=1.1\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/a8/87/77cc11c7a9ea9fd05503def69e3d18605852cd0d4b0d3b8f15bbeb3ef1d1/pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting lazy_loader>=0.1\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/83/60/d497a310bde3f01cb805196ac61b7ad6dc5dcf8dce66634dc34364b20b4f/lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Collecting scikit-learn>=1.1.0\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/b7/91/ab3c697188f224d658969f678be86b0968ccc52774c8ab4a86a07be13c25/scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m258.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: decorator>=4.3.0 in ./miniconda3/lib/python3.10/site-packages (from librosa) (5.2.1)\n",
      "Collecting soxr>=0.3.2\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/ba/e6/059070b4cdb7fdd8ffbb67c5087c1da9716577127fb0540cd11dbf77923b/soxr-0.5.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (252 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.8/252.8 kB\u001b[0m \u001b[31m185.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting soundfile>=0.12.1\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/57/5e/70bdd9579b35003a489fc850b5047beeda26328053ebadc1fb60f320f7db/soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m286.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scipy>=1.6.0\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/8e/6d/41991e503e51fc1134502694c5fa7a1671501a17ffa12716a4a9151af3df/scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m123.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting msgpack>=1.0\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/ff/75/09081792db60470bef19d9c2be89f024d366b1e1973c197bb59e6aabc647/msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.0/378.0 kB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22.3 in ./miniconda3/lib/python3.10/site-packages (from librosa) (2.2.5)\n",
      "Collecting typeguard>=4.0.1\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/cf/4b/9a77dc721aa0b7f74440a42e4ef6f9a4fae7324e17f64f88b96f4c25cc05/typeguard-4.4.2-py3-none-any.whl (35 kB)\n",
      "Collecting more_itertools>=8.5.0\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/2b/9f/7ba6f94fc1e9ac3d2b853fdff3035fb2fa5afbed898c4a72b8a020610594/more_itertools-10.7.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf>=3.20.2\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/28/50/1925de813499546bc8ab3ae857e3ec84efe7d2f19b34529d0c7c3d02d11d/protobuf-6.30.2-cp39-abi3-manylinux2014_x86_64.whl (316 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.2/316.2 kB\u001b[0m \u001b[31m204.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting coloredlogs\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/a7/06/3d6badcf13db419e25b07041d9c7b4a2c331d3f4e7134445ec5df57714cd/coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sympy in ./miniconda3/lib/python3.10/site-packages (from onnxruntime) (1.14.0)\n",
      "Collecting flatbuffers\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/b8/25/155f9f080d5e4bc0082edfda032ea2bc2b8fab3f4d25d46c1e9dd22a1a89/flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: packaging in ./miniconda3/lib/python3.10/site-packages (from onnxruntime) (23.1)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/aa/46/8ffbc114def88cc698906bf5acab54ca9fdf9214fe04aed0e71731fb3688/llvmlite-0.44.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in ./miniconda3/lib/python3.10/site-packages (from pooch>=1.1->librosa) (2.31.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in ./miniconda3/lib/python3.10/site-packages (from pooch>=1.1->librosa) (4.3.8)\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/32/d5/f9a850d79b0851d1d4ef6456097579a9005b31fea68726a4ae5f2d82ddd9/threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in ./miniconda3/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Collecting humanfriendly>=9.1\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/f0/0f/310fb31e39e2d734ccaa2c0fb981ee41f7bd5056ce9bc29b2248bd569169/humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting csvw>=1.5.6\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/13/84/069db1325f5a6dd034524c0099da3978de8fdb6242ce63223ead188da940/csvw-3.5.1-py2.py3-none-any.whl (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting regex\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/f2/98/26d3830875b53071f1f0ae6d547f1d98e964dd29ad35cbf94439120bb67a/regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m119.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mpmath<1.4,>=1.1.0 in ./miniconda3/lib/python3.10/site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Requirement already satisfied: pycparser in ./miniconda3/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Collecting colorama\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/d1/d6/3965ed04c63042e047cb6a3e6ed1a63a35087b6a609aa3a15ed8ac56c221/colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: babel in ./miniconda3/lib/python3.10/site-packages (from csvw>=1.5.6->segments->phonemizer) (2.17.0)\n",
      "Collecting rfc3986<2\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/c4/e5/63ca2c4edf4e00657584608bee1001302bbf8c5f569340b78304f2f446cb/rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting isodate\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/15/aa/0aca39a37d3c7eb941ba736ede56d689e7be91cab5d9ca846bde3999eba6/isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "Collecting uritemplate>=3.0.0\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/81/c0/7461b49cd25aeece13766f02ee576d1db528f1c37ce69aee300e075b485b/uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting language-tags\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/b0/42/327554649ed2dd5ce59d3f5da176c7be20f9352c7c6c51597293660b7b08/language_tags-1.2.0-py3-none-any.whl (213 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.4/213.4 kB\u001b[0m \u001b[31m166.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jsonschema in ./miniconda3/lib/python3.10/site-packages (from csvw>=1.5.6->segments->phonemizer) (4.23.0)\n",
      "Collecting rdflib\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/f4/31/e9b6f04288dcd3fa60cb3179260d6dad81b92aef3063d679ac7d80a827ea/rdflib-7.1.4-py3-none-any.whl (565 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.1/565.1 kB\u001b[0m \u001b[31m232.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil in ./miniconda3/lib/python3.10/site-packages (from csvw>=1.5.6->segments->phonemizer) (2.9.0.post0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./miniconda3/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./miniconda3/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniconda3/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./miniconda3/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./miniconda3/lib/python3.10/site-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (0.36.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./miniconda3/lib/python3.10/site-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (2025.4.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./miniconda3/lib/python3.10/site-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (0.24.0)\n",
      "Requirement already satisfied: six>=1.5 in ./miniconda3/lib/python3.10/site-packages (from python-dateutil->csvw>=1.5.6->segments->phonemizer) (1.17.0)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in ./miniconda3/lib/python3.10/site-packages (from rdflib->csvw>=1.5.6->segments->phonemizer) (3.2.3)\n",
      "Installing collected packages: rfc3986, language-tags, flatbuffers, uritemplate, Unidecode, typeguard, threadpoolctl, soxr, scipy, regex, protobuf, piper_phonemize, msgpack, more_itertools, llvmlite, lazy_loader, joblib, isodate, humanfriendly, dlinfo, colorama, audioread, soundfile, scikit-learn, rdflib, pooch, onnx, numba, inflect, coloredlogs, onnxruntime, librosa, csvw, segments, phonemizer\n",
      "Successfully installed Unidecode-1.4.0 audioread-3.0.1 colorama-0.4.6 coloredlogs-15.0.1 csvw-3.5.1 dlinfo-2.0.0 flatbuffers-25.2.10 humanfriendly-10.0 inflect-7.5.0 isodate-0.7.2 joblib-1.5.0 language-tags-1.2.0 lazy_loader-0.4 librosa-0.11.0 llvmlite-0.44.0 more_itertools-10.7.0 msgpack-1.1.0 numba-0.61.2 onnx-1.17.0 onnxruntime-1.21.1 phonemizer-3.3.0 piper_phonemize-1.1.0 pooch-1.8.2 protobuf-6.30.2 rdflib-7.1.4 regex-2024.11.6 rfc3986-1.5.0 scikit-learn-1.6.1 scipy-1.15.3 segments-2.3.0 soundfile-0.13.1 soxr-0.5.0.post1 threadpoolctl-3.6.0 typeguard-4.4.2 uritemplate-4.1.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Manually install dependencies\n",
    "!pip install phonemizer Unidecode librosa tqdm inflect onnx onnxruntime piper_phonemize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME=\"Red Hat Enterprise Linux\"\n",
      "VERSION=\"9.4 (Plow)\"\n",
      "ID=\"rhel\"\n",
      "ID_LIKE=\"fedora\"\n",
      "VERSION_ID=\"9.4\"\n",
      "PLATFORM_ID=\"platform:el9\"\n",
      "PRETTY_NAME=\"Red Hat Enterprise Linux 9.4 (Plow)\"\n",
      "ANSI_COLOR=\"0;31\"\n",
      "LOGO=\"fedora-logo-icon\"\n",
      "CPE_NAME=\"cpe:/o:redhat:enterprise_linux:9::baseos\"\n",
      "HOME_URL=\"https://www.redhat.com/\"\n",
      "DOCUMENTATION_URL=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9\"\n",
      "BUG_REPORT_URL=\"https://bugzilla.redhat.com/\"\n",
      "\n",
      "REDHAT_BUGZILLA_PRODUCT=\"Red Hat Enterprise Linux 9\"\n",
      "REDHAT_BUGZILLA_PRODUCT_VERSION=9.4\n",
      "REDHAT_SUPPORT_PRODUCT=\"Red Hat Enterprise Linux\"\n",
      "REDHAT_SUPPORT_PRODUCT_VERSION=\"9.4\"\n",
      "Red Hat Enterprise Linux release 9.4 (Plow)\n",
      "Red Hat Enterprise Linux release 9.4 (Plow)\n"
     ]
    }
   ],
   "source": [
    "!cat /etc/*release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GgFF3-iLcIO1",
    "outputId": "0d977e08-1fb0-4427-c0c9-976d61173413"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "We trust you have received the usual lecture from the local System\n",
      "Administrator. It usually boils down to these three things:\n",
      "\n",
      "    #1) Respect the privacy of others.\n",
      "    #2) Think before you type.\n",
      "    #3) With great power comes great responsibility.\n",
      "\n",
      "[sudo] password for praval: \n",
      "sudo: timed out reading password\n",
      "sudo: a password is required\n"
     ]
    }
   ],
   "source": [
    "#!sudo yum install -y espeak-ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TTH8BXIgXk0D"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/piper/src/python')\n",
    "\n",
    "# !ls /content/piper/src/python/piper_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Q0Sym-Cta1pD",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# !ls /content/input/wavs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/praval'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/praval/piper/src/python\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/praval/miniconda3/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd piper/src/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/praval/piper/src/python'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VfTlT8gFhRTd",
    "outputId": "63a9c695-0812-4d20-88cb-a53f8b1049d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:preprocess:Single speaker dataset\n",
      "INFO:preprocess:Wrote dataset config\n",
      "INFO:preprocess:Processing 4627 utterance(s) with 128 worker(s)\n",
      "max value is  tensor(1.0100)\n",
      "min value is  tensor(-1.0102)\n",
      "min value is  tensor(-1.0257)\n",
      "max value is  tensor(1.0102)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!PYTHONPATH=. python3 -m piper_train.preprocess \\\n",
    "  --language hi \\\n",
    "  --input-dir ../../../dataset/input/mono/Read_speech \\\n",
    "  --output-dir training_dir \\\n",
    "  --dataset-format ljspeech \\\n",
    "  --single-speaker \\\n",
    "  --sample-rate 22050\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w7xpSPC6vtBP",
    "outputId": "3ce6c480-2001-4aee-fef2-b499f50347c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://odpd.sac.gov.in/offline-pypi-mirror/simple/\n",
      "Collecting pytorch_lightning\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/de/a9/e14821cfaf08e8d78185cca0477c9d3a62bafe1b4b530100f7b66bb1f7bb/pytorch_lightning-2.5.1.post0-py3-none-any.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.1/823.1 kB\u001b[0m \u001b[31m200.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cython\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/dc/21/5b700dac60cc7af4261c7fa2e91f55fe5f38f6c183e1201ced7cc932201b/Cython-3.0.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m248.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.57.0 in ./miniconda3/lib/python3.10/site-packages (from pytorch_lightning) (4.65.0)\n",
      "Requirement already satisfied: fsspec[http]>=2022.5.0 in ./miniconda3/lib/python3.10/site-packages (from pytorch_lightning) (2025.3.2)\n",
      "Requirement already satisfied: torch>=2.1.0 in ./miniconda3/lib/python3.10/site-packages (from pytorch_lightning) (2.5.1)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in ./miniconda3/lib/python3.10/site-packages (from pytorch_lightning) (4.13.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./miniconda3/lib/python3.10/site-packages (from pytorch_lightning) (23.1)\n",
      "Collecting torchmetrics>=0.7.0\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/e0/ee/4d0a7213a6f412afb3483031009a3b970dd7bed3be24de95ab04fba1c05a/torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m237.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting lightning-utilities>=0.10.0\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/1a/c1/31b3184cba7b257a4a3b5ca5b88b9204ccb7aa02fe3c992280899293ed54/lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: PyYAML>=5.4 in ./miniconda3/lib/python3.10/site-packages (from pytorch_lightning) (6.0.2)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/e0/ab/40dacb15c0c58f7f17686ea67bc186e9f207341691bdb777d1d5ff4671d5/aiohttp-3.11.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m218.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in ./miniconda3/lib/python3.10/site-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (68.0.0)\n",
      "Requirement already satisfied: triton==3.1.0 in ./miniconda3/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (3.1.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./miniconda3/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (12.3.1.170)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./miniconda3/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./miniconda3/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./miniconda3/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./miniconda3/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./miniconda3/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./miniconda3/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (9.1.0.70)\n",
      "Requirement already satisfied: filelock in ./miniconda3/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (3.18.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./miniconda3/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./miniconda3/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (2.21.5)\n",
      "Requirement already satisfied: networkx in ./miniconda3/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./miniconda3/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
      "Requirement already satisfied: jinja2 in ./miniconda3/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./miniconda3/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./miniconda3/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./miniconda3/lib/python3.10/site-packages (from torch>=2.1.0->pytorch_lightning) (11.2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./miniconda3/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.1.0->pytorch_lightning) (1.3.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in ./miniconda3/lib/python3.10/site-packages (from torchmetrics>=0.7.0->pytorch_lightning) (2.2.5)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/ec/6a/bc7e17a3e87a2985d3e8f4da4cd0f481060eb78fb08596c42be62c90a4d9/aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./miniconda3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (25.3.0)\n",
      "Collecting async-timeout<6.0,>=4.0\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/fe/ba/e2081de779ca30d473f21f5b30e0e737c438205440784c7dfc81efc2b029/async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/2c/e9/40d2b73e7d6574d91074d83477a990e3701affbe8b596010d4f5e6c7a6fa/multidict-6.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (219 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.8/219.8 kB\u001b[0m \u001b[31m161.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiohappyeyeballs>=2.3.0\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/0f/15/5bf3b99495fb160b63f95972b81750f18f7f4e02ad051373b669d17d44f2/aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/d0/6e/1b64671ab2fca1ebf32c5b500205724ac14c98b9bc1574b2ef55853f4d71/frozenlist-1.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.3/287.3 kB\u001b[0m \u001b[31m180.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting propcache>=0.2.0\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/7c/e4/4aeb95a1cd085e0558ab0de95abfc5187329616193a1012a6c4c930e9f7a/propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (206 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.6/206.6 kB\u001b[0m \u001b[31m156.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.17.0\n",
      "  Downloading https://odpd.sac.gov.in/offline-pypi-mirror/packages/8b/fd/10fcf7d86f49b1a11096d6846257485ef32e3d3d322e8a7fdea5b127880c/yarl-1.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (333 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m333.9/333.9 kB\u001b[0m \u001b[31m189.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in ./miniconda3/lib/python3.10/site-packages (from jinja2->torch>=2.1.0->pytorch_lightning) (3.0.2)\n",
      "Requirement already satisfied: idna>=2.0 in ./miniconda3/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.4)\n",
      "Installing collected packages: propcache, multidict, lightning-utilities, frozenlist, cython, async-timeout, aiohappyeyeballs, yarl, aiosignal, aiohttp, torchmetrics, pytorch_lightning\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 async-timeout-5.0.1 cython-3.0.12 frozenlist-1.6.0 lightning-utilities-0.14.3 multidict-6.4.3 propcache-0.3.1 pytorch_lightning-2.5.1.post0 torchmetrics-1.7.1 yarl-1.20.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Looking in indexes: https://odpd.sac.gov.in/offline-pypi-mirror/simple/\n",
      "Requirement already satisfied: torchvision==0.20.1 in ./miniconda3/lib/python3.10/site-packages (0.20.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./miniconda3/lib/python3.10/site-packages (from torchvision==0.20.1) (11.2.1)\n",
      "Requirement already satisfied: torch==2.5.1 in ./miniconda3/lib/python3.10/site-packages (from torchvision==0.20.1) (2.5.1)\n",
      "Requirement already satisfied: numpy in ./miniconda3/lib/python3.10/site-packages (from torchvision==0.20.1) (2.2.5)\n",
      "Requirement already satisfied: filelock in ./miniconda3/lib/python3.10/site-packages (from torch==2.5.1->torchvision==0.20.1) (3.18.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./miniconda3/lib/python3.10/site-packages (from torch==2.5.1->torchvision==0.20.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./miniconda3/lib/python3.10/site-packages (from torch==2.5.1->torchvision==0.20.1) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./miniconda3/lib/python3.10/site-packages (from torch==2.5.1->torchvision==0.20.1) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./miniconda3/lib/python3.10/site-packages (from torch==2.5.1->torchvision==0.20.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./miniconda3/lib/python3.10/site-packages (from torch==2.5.1->torchvision==0.20.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./miniconda3/lib/python3.10/site-packages (from torch==2.5.1->torchvision==0.20.1) (12.4.127)\n",
      "Requirement already satisfied: jinja2 in ./miniconda3/lib/python3.10/site-packages (from torch==2.5.1->torchvision==0.20.1) (3.1.6)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./miniconda3/lib/python3.10/site-packages (from torch==2.5.1->torchvision==0.20.1) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./miniconda3/lib/python3.10/site-packages (from torch==2.5.1->torchvision==0.20.1) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./miniconda3/lib/python3.10/site-packages (from torch==2.5.1->torchvision==0.20.1) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./miniconda3/lib/python3.10/site-packages (from torch==2.5.1->torchvision==0.20.1) (12.4.127)\n",
      "Requirement already satisfied: fsspec in ./miniconda3/lib/python3.10/site-packages (from torch==2.5.1->torchvision==0.20.1) (2025.3.2)\n",
      "Requirement already satisfied: triton==3.1.0 in ./miniconda3/lib/python3.10/site-packages (from torch==2.5.1->torchvision==0.20.1) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./miniconda3/lib/python3.10/site-packages (from torch==2.5.1->torchvision==0.20.1) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./miniconda3/lib/python3.10/site-packages (from torch==2.5.1->torchvision==0.20.1) (12.4.5.8)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./miniconda3/lib/python3.10/site-packages (from torch==2.5.1->torchvision==0.20.1) (4.13.2)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./miniconda3/lib/python3.10/site-packages (from torch==2.5.1->torchvision==0.20.1) (10.3.5.147)\n",
      "Requirement already satisfied: networkx in ./miniconda3/lib/python3.10/site-packages (from torch==2.5.1->torchvision==0.20.1) (3.4.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./miniconda3/lib/python3.10/site-packages (from sympy==1.13.1->torch==2.5.1->torchvision==0.20.1) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./miniconda3/lib/python3.10/site-packages (from jinja2->torch==2.5.1->torchvision==0.20.1) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_lightning cython\n",
    "!pip install torchvision==0.20.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9Tezk0kAIaef"
   },
   "outputs": [],
   "source": [
    "# !rm -rf dataset/input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/praval/piper/src/python'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/praval/piper/src/python/temp_build\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p temp_build\n",
    "!cp piper_train/vits/monotonic_align/core.pyx temp_build/\n",
    "!cp piper_train/vits/monotonic_align/setup.py temp_build/\n",
    "%cd temp_build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/praval/piper/src/python/temp_build'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "guWq3XUgzeQ_",
    "outputId": "8bcd42b6-6e56-4c5e-9d8b-e98b869ee06f"
   },
   "outputs": [],
   "source": [
    "!python3 setup.py build_ext --inplace\n",
    "# Copy .so back\n",
    "!cp core*.so ../piper_train/vits/monotonic_align/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6g5YbZL60jLg",
    "outputId": "e7006153-4484-460b-8a5c-10558c676607"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "core.c\t\t\t\t      core.pyx\t   Makefile\tsetup.py\n",
      "core.cpython-310-x86_64-linux-gnu.so  __init__.py  __pycache__\n"
     ]
    }
   ],
   "source": [
    "!ls piper_train/vits/monotonic_align/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P_XihnkgPFrF",
    "outputId": "1a637ce2-78c9-4304-f952-65beda575748"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pytorch-lightning\n",
      "Version: 1.9.5\n",
      "Summary: PyTorch Lightning is the lightweight PyTorch wrapper for ML researchers. Scale your models. Write less boilerplate.\n",
      "Home-page: https://github.com/Lightning-AI/lightning\n",
      "Author: Lightning AI et al.\n",
      "Author-email: pytorch@lightning.ai\n",
      "License: Apache-2.0\n",
      "Location: /home/praval/miniconda3/lib/python3.10/site-packages\n",
      "Requires: fsspec, lightning-utilities, numpy, packaging, PyYAML, torch, torchmetrics, tqdm, typing-extensions\n",
      "Required-by: \n",
      "---\n",
      "Name: torchmetrics\n",
      "Version: 1.7.1\n",
      "Summary: PyTorch native Metrics\n",
      "Home-page: https://github.com/Lightning-AI/torchmetrics\n",
      "Author: Lightning-AI et al.\n",
      "Author-email: name@pytorchlightning.ai\n",
      "License: Apache-2.0\n",
      "Location: /home/praval/miniconda3/lib/python3.10/site-packages\n",
      "Requires: lightning-utilities, numpy, packaging, torch\n",
      "Required-by: pytorch-lightning\n"
     ]
    }
   ],
   "source": [
    "!pip show pytorch-lightning torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ok1j7K37eHpG",
    "outputId": "002e2e9c-b0a3-494b-a9d3-7a482469efdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.5.1\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3-Clause\n",
      "Location: /home/praval/miniconda3/lib/python3.10/site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, nvidia-cublas-cu12, nvidia-cuda-cupti-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-runtime-cu12, nvidia-cudnn-cu12, nvidia-cufft-cu12, nvidia-curand-cu12, nvidia-cusolver-cu12, nvidia-cusparse-cu12, nvidia-nccl-cu12, nvidia-nvjitlink-cu12, nvidia-nvtx-cu12, sympy, triton, typing-extensions\n",
      "Required-by: pytorch-lightning, torchaudio, torchmetrics, torchvision\n",
      "---\n",
      "Name: torchvision\n",
      "Version: 0.20.1\n",
      "Summary: image and video datasets and models for torch deep learning\n",
      "Home-page: https://github.com/pytorch/vision\n",
      "Author: PyTorch Core Team\n",
      "Author-email: soumith@pytorch.org\n",
      "License: BSD\n",
      "Location: /home/praval/miniconda3/lib/python3.10/site-packages\n",
      "Requires: numpy, pillow, torch\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L-MeBmMlR9SK",
    "outputId": "acf1f372-9b2c-442d-91dd-af55b31aad1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://odpd.sac.gov.in/offline-pypi-mirror/simple/\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torchmetrics==0.9.3 (from versions: 1.4.3, 1.5.0, 1.5.1, 1.5.2, 1.6.0, 1.6.1, 1.6.2, 1.6.3, 1.7.0, 1.7.1)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torchmetrics==0.9.3\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics==0.9.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "58lcZFGFUOrU",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "e96a28f0-d03a-4429-f309-185b45517f9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.26.0\n",
      "  Downloading numpy-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.0\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/praval/piper/src/python\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/praval/miniconda3/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd /home/praval/piper/src/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iQJasbBUYqqL",
    "outputId": "0806cd1e-0faf-42d5-c348-88ec8cd2185e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_symbols: 256\n",
      "num_speakers: 1\n",
      "sample_rate: 22050\n"
     ]
    }
   ],
   "source": [
    " import json\n",
    " config_path = 'training_dir/config.json'\n",
    " dataset_path = 'training_dir/dataset.jsonl'\n",
    "\n",
    "with open(config_path, \"r\", encoding=\"utf-8\") as config_file:\n",
    "    # See preprocess.py for format\n",
    "    config = json.load(config_file)\n",
    "    num_symbols = int(config[\"num_symbols\"])\n",
    "    num_speakers = int(config[\"num_speakers\"])\n",
    "    sample_rate = int(config[\"audio\"][\"sample_rate\"])\n",
    "    print(f\"num_symbols: {num_symbols}\")\n",
    "    print(f\"num_speakers: {num_speakers}\")\n",
    "    print(f\"sample_rate: {sample_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rdepHZdaomLh"
   },
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# shutil.copytree('/content/drive/MyDrive/training_dir', '/content/train_dir/wavs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/praval/piper/src/python'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RJ1Qe7benrE5",
    "outputId": "954e5641-a116-4500-e5ef-2fd6eb66d213"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:piper_train:Namespace(dataset_dir='training_dir', checkpoint_epochs=1, quality='medium', resume_from_single_speaker_checkpoint=None, logger=True, enable_checkpointing=True, default_root_dir=None, gradient_clip_val=None, gradient_clip_algorithm=None, num_nodes=1, num_processes=None, devices='1', gpus=None, auto_select_gpus=None, tpu_cores=None, ipus=None, enable_progress_bar=True, overfit_batches=0.0, track_grad_norm=-1, check_val_every_n_epoch=1, fast_dev_run=False, accumulate_grad_batches=None, max_epochs=10000, min_epochs=None, max_steps=-1, min_steps=None, max_time=None, limit_train_batches=None, limit_val_batches=None, limit_test_batches=None, limit_predict_batches=None, val_check_interval=None, log_every_n_steps=50, accelerator='gpu', strategy=None, sync_batchnorm=False, precision=32, enable_model_summary=True, num_sanity_val_steps=2, resume_from_checkpoint='tuning/epoch=2692-step=1775828.ckpt', profiler=None, benchmark=None, reload_dataloaders_every_n_epochs=0, auto_lr_find=False, replace_sampler_ddp=True, detect_anomaly=False, auto_scale_batch_size=False, plugins=None, amp_backend=None, amp_level=None, move_metrics_to_cpu=False, multiple_trainloader_mode='max_size_cycle', inference_mode=True, batch_size=32, validation_split=0.0, num_test_examples=0, max_phoneme_ids=None, hidden_channels=192, inter_channels=192, filter_channels=768, n_layers=6, n_heads=2, seed=1234)\n",
      "/home/praval/miniconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:55: LightningDeprecationWarning: Setting `Trainer(resume_from_checkpoint=)` is deprecated in v1.5 and will be removed in v2.0. Please pass `Trainer.fit(ckpt_path=)` directly instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "DEBUG:piper_train:Checkpoints will be saved every 1 epoch(s)\n",
      "/home/praval/miniconda3/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "DEBUG:vits.dataset:Loading dataset: training_dir/dataset.jsonl\n",
      "/home/praval/miniconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1906: LightningDeprecationWarning: `trainer.resume_from_checkpoint` is deprecated in v1.5 and will be removed in v2.0. Specify the fit checkpoint path with `trainer.fit(ckpt_path=)` instead.\n",
      "  rank_zero_deprecation(\n",
      "You are using a CUDA device ('NVIDIA A100 80GB PCIe') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Restoring states from the checkpoint path at tuning/epoch=2692-step=1775828.ckpt\n",
      "DEBUG:fsspec.local:open file: /home/praval/piper/src/python/tuning/epoch=2692-step=1775828.ckpt\n",
      "/home/praval/miniconda3/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:51: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location)  # type: ignore[arg-type]\n",
      "/home/praval/miniconda3/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:338: UserWarning: The dirpath has changed from 'training_dir/lightning_logs/version_16/checkpoints' to 'training_dir/lightning_logs/version_23/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n",
      "  warnings.warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "2025-06-12 16:16:37.035200: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-12 16:16:37.046973: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749725197.059990  829166 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749725197.063522  829166 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749725197.073706  829166 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749725197.073725  829166 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749725197.073727  829166 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749725197.073729  829166 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-12 16:16:37.076962: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "DEBUG:tensorflow:Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
      "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
      "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
      "DEBUG:h5py._conv:Creating converter from 7 to 5\n",
      "DEBUG:h5py._conv:Creating converter from 5 to 7\n",
      "DEBUG:fsspec.local:open file: /home/praval/piper/src/python/training_dir/lightning_logs/version_23/hparams.yaml\n",
      "Restored all states from the checkpoint file at tuning/epoch=2692-step=1775828.ckpt\n",
      "/home/praval/miniconda3/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:109: UserWarning: Total length of `DataLoader` across ranks is zero. Please make sure this was your intention.\n",
      "  rank_zero_warn(\n",
      "/home/praval/miniconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 128 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Epoch 2693 started\n",
      "/home/praval/piper/src/python/piper_train/vits/dataset.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  audio_norm=torch.load(utt.audio_norm_path),\n",
      "/home/praval/piper/src/python/piper_train/vits/dataset.py:81: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  spectrogram=torch.load(utt.audio_spec_path),\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/praval/piper/src/python/piper_train/__main__.py\", line 159, in <module>\n",
      "    main()\n",
      "  File \"/home/praval/piper/src/python/piper_train/__main__.py\", line 136, in main\n",
      "    trainer.fit(model)\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 608, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 38, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 650, in _fit_impl\n",
      "    self._run(model, ckpt_path=self.ckpt_path)\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1112, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1191, in _run_stage\n",
      "    self._run_train()\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1214, in _run_train\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py\", line 267, in advance\n",
      "    self._outputs = self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 213, in advance\n",
      "    batch_output = self.batch_loop.run(kwargs)\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 88, in advance\n",
      "    outputs = self.optimizer_loop.run(optimizers, kwargs)\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py\", line 199, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 202, in advance\n",
      "    result = self._run_optimization(kwargs, self._optimizers[self.optim_progress.optimizer_position])\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 249, in _run_optimization\n",
      "    self._optimizer_step(optimizer, opt_idx, kwargs.get(\"batch_idx\", 0), closure)\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 370, in _optimizer_step\n",
      "    self.trainer._call_lightning_module_hook(\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1356, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/pytorch_lightning/core/module.py\", line 1754, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py\", line 169, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py\", line 234, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 119, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/torch/optim/lr_scheduler.py\", line 137, in wrapper\n",
      "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 487, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 91, in _use_grad\n",
      "    ret = func(self, *args, **kwargs)\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/torch/optim/adamw.py\", line 197, in step\n",
      "    loss = closure()\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 105, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 149, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 135, in closure\n",
      "    step_output = self._step_fn()\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 419, in _training_step\n",
      "    training_step_output = self.trainer._call_strategy_hook(\"training_step\", *kwargs.values())\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1494, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py\", line 378, in training_step\n",
      "    return self.model.training_step(*args, **kwargs)\n",
      "  File \"/home/praval/piper/src/python/piper_train/vits/lightning.py\", line 191, in training_step\n",
      "    return self.training_step_g(batch)\n",
      "  File \"/home/praval/piper/src/python/piper_train/vits/lightning.py\", line 214, in training_step_g\n",
      "    ) = self.model_g(x, x_lengths, spec, spec_lengths, speaker_ids)\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/praval/piper/src/python/piper_train/vits/models.py\", line 619, in forward\n",
      "    x, m_p, logs_p, x_mask = self.enc_p(x, x_lengths)\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/praval/piper/src/python/piper_train/vits/models.py\", line 205, in forward\n",
      "    x = self.encoder(x * x_mask, x_mask)\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/praval/piper/src/python/piper_train/vits/attentions.py\", line 66, in forward\n",
      "    y = attn_layer(x, x, attn_mask)\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/praval/piper/src/python/piper_train/vits/attentions.py\", line 220, in forward\n",
      "    x, self.attn = self.attention(q, k, v, mask=attn_mask)\n",
      "  File \"/home/praval/piper/src/python/piper_train/vits/attentions.py\", line 262, in attention\n",
      "    relative_weights = self._absolute_position_to_relative_position(p_attn)\n",
      "  File \"/home/praval/piper/src/python/piper_train/vits/attentions.py\", line 342, in _absolute_position_to_relative_position\n",
      "    x = F.pad(x, (0, length - 1, 0, 0, 0, 0, 0, 0))\n",
      "  File \"/home/praval/miniconda3/lib/python3.10/site-packages/torch/nn/functional.py\", line 5096, in pad\n",
      "    return torch._C._nn.pad(input, pad, mode, value)\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 10.45 GiB. GPU 0 has a total capacity of 79.14 GiB of which 2.45 GiB is free. Including non-PyTorch memory, this process has 76.66 GiB memory in use. Of the allocated memory 69.58 GiB is allocated by PyTorch, and 6.57 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    }
   ],
   "source": [
    "!PYTHONPATH=. python3 -m piper_train \\\n",
    "  --dataset-dir training_dir \\\n",
    "  --accelerator 'gpu' \\\n",
    "  --devices 1 \\\n",
    "  --batch-size 32 \\\n",
    "  --validation-split 0.0 \\\n",
    "  --num-test-examples 0 \\\n",
    "  --max_epochs 10000 \\\n",
    "  --resume_from_checkpoint tuning/epoch=2692-step=1775828.ckpt \\\n",
    "  --checkpoint-epochs 1 \\\n",
    "  --precision 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "77QjfvUQJ-1_",
    "outputId": "5021553d-2234-4809-e3e7-84cf3e09ae28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4627 /content/drive/MyDrive/training_dir/dataset.jsonl\n"
     ]
    }
   ],
   "source": [
    "!wc -l /content/drive/MyDrive/training_dir/dataset.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ABYvKK0nKN7v",
    "outputId": "fe4fd461-376a-4ee7-b60a-37dafcceae7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples found: 4627\n",
      "Example: {'text': 'male', 'audio_path': '/content/input/wavs/train_hindifullmale_01735.wav', 'speaker': None, 'speaker_id': None, 'phonemes': ['m', 'ˈ', 'e', 'ɪ', 'l'], 'phoneme_ids': [1, 0, 25, 0, 120, 0, 18, 0, 74, 0, 24, 0, 2], 'audio_norm_path': '/content/drive/MyDrive/training_dir/cache/22050/cab7ca68d989403be76e9d53776b9e098336878081fe627314f1b9c2284e0686.pt', 'audio_spec_path': '/content/drive/MyDrive/training_dir/cache/22050/cab7ca68d989403be76e9d53776b9e098336878081fe627314f1b9c2284e0686.spec.pt'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('/content/drive/MyDrive/training_dir/dataset.jsonl') as f:\n",
    "    lines = [json.loads(line) for line in f]\n",
    "print(\"Samples found:\", len(lines))\n",
    "print(\"Example:\", lines[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "collapsed": true,
    "id": "YpwQcTxFQzJ3",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "dda87339-c43f-42fd-9d3b-1d0613701d0d"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lines' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8ca8cbb035fa>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'audio_spec_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'audio_norm_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Missing files:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lines' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "missing = [line for line in lines if not (os.path.exists(line['audio_spec_path']) and os.path.exists(line['audio_norm_path']))]\n",
    "print(\"Missing files:\", len(missing))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2oWNXrHYR6JW",
    "outputId": "ef58fc35-f679-4dae-afc3-e287b5e83939"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['dataset', 'audio', 'espeak', 'language', 'inference', 'phoneme_type', 'phoneme_map', 'phoneme_id_map', 'num_symbols', 'num_speakers', 'speaker_id_map', 'piper_version'])\n",
      "Sample rate: None\n",
      "Phoneme language: None\n",
      "Use phonemes: None\n",
      "Training dataset path: None\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/content/drive/MyDrive/training_dir/config.json\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "print(cfg.keys())\n",
    "print(\"Sample rate:\", cfg.get(\"sample_rate\"))\n",
    "print(\"Phoneme language:\", cfg.get(\"phoneme_language\"))\n",
    "print(\"Use phonemes:\", cfg.get(\"use_phonemes\"))\n",
    "print(\"Training dataset path:\", cfg.get(\"train_metadata\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PHJEjmejSpM-",
    "outputId": "028fdc42-3689-4dc6-c5fc-1be257d5e22e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: MyDrive\n",
      "audio: {'sample_rate': 22050, 'quality': 'training_dir'}\n",
      "espeak: {'voice': 'hi'}\n",
      "language: {'code': 'hi'}\n",
      "phoneme_type: espeak\n",
      "num_speakers: 1\n",
      "speaker_id_map: {}\n",
      "Sample rate: 22050\n",
      "Phoneme type: espeak\n",
      "ESpeak voice: hi\n",
      "Language code: hi\n",
      "Number of speakers: 1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/content/drive/MyDrive/training_dir/config.json\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "print(\"dataset:\", cfg.get(\"dataset\"))\n",
    "print(\"audio:\", cfg.get(\"audio\"))\n",
    "print(\"espeak:\", cfg.get(\"espeak\"))\n",
    "print(\"language:\", cfg.get(\"language\"))\n",
    "print(\"phoneme_type:\", cfg.get(\"phoneme_type\"))\n",
    "print(\"num_speakers:\", cfg.get(\"num_speakers\"))\n",
    "print(\"speaker_id_map:\", cfg.get(\"speaker_id_map\"))\n",
    "print(\"Sample rate:\", cfg[\"audio\"][\"sample_rate\"])\n",
    "print(\"Phoneme type:\", cfg[\"phoneme_type\"])\n",
    "print(\"ESpeak voice:\", cfg[\"espeak\"][\"voice\"])\n",
    "print(\"Language code:\", cfg[\"language\"][\"code\"])\n",
    "print(\"Number of speakers:\", cfg[\"num_speakers\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0mGcSQCeEAxz",
    "outputId": "d481daad-0c28-4e82-bea9-dc21bf64e936"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_hindifullmale_00001|प्रसिद्द कबीर अध्येता, पुरुषोत्तम अग्रवाल का यह शोध आलेख, उस रामानंद की खोज करता है|male\n",
      "train_hindifullmale_00002|किन्तु आधुनिक पांडित्य, न सिर्फ़ एक ब्राह्मण रामानंद के, एक जुलाहे कबीर का गुरु होने से, बल्कि दोनों के समकालीन होने से भी, इनकार करता है|male\n",
      "train_hindifullmale_00003|उस पर, इन चार कवियों का गहरा असर है|male\n",
      "train_hindifullmale_00004|इसे कई बार, मंचित भी किया गया है|male\n",
      "train_hindifullmale_00005|यहाँ प्रस्तुत है, हिन्दी कवि कथाकार, तेजी ग्रोवर के अंग्रेज़ी के मार्फ़त किए गए अनुवाद के कुछ अंश|male\n"
     ]
    }
   ],
   "source": [
    "with open(\"/content/input/metadata.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        print(line.strip())\n",
    "        if i == 4:  # Show only first 5 lines\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "75SPmdLLZJpB",
    "outputId": "3b5b447e-1c76-4283-bec6-53baf39ac9b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing files: 0\n",
      "Example missing: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "missing = []\n",
    "with open(\"/content/input/metadata.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        fname = line.strip().split(\"|\")[0]\n",
    "        wav_path = f\"/content/input/wavs/{fname}.wav\"\n",
    "        if not os.path.exists(wav_path):\n",
    "            missing.append(fname)\n",
    "\n",
    "print(f\"Total missing files: {len(missing)}\")\n",
    "print(\"Example missing:\", missing[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "UzBVno8hWYAL",
    "outputId": "d1f649ee-8a4b-4c62-bc7d-9558803a7b71",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 12 16:14:53 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          Off |   00000000:27:00.0 Off |                    0 |\n",
      "| N/A   47C    P0             47W /  300W |      13MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA T400 4GB                Off |   00000000:C8:00.0 Off |                  N/A |\n",
      "| 46%   58C    P8             N/A /   31W |     192MiB /   4096MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      3497      G   /usr/libexec/Xorg                               4MiB |\n",
      "|    1   N/A  N/A      3497      G   /usr/libexec/Xorg                             182MiB |\n",
      "|    1   N/A  N/A      3535      G   /usr/bin/gnome-shell                            7MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 🩹 Fix Piper Trainer Compatibility\n",
    "import os\n",
    "\n",
    "# Define path to the file\n",
    "file_path = \"piper_repo/src/python/piper_train/__main__.py\"\n",
    "\n",
    "# The CORRECTED content (Lightning 2.x compatible)\n",
    "new_content = \"\"\"import argparse\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from .vits.lightning import VitsModel\n",
    "\n",
    "_LOGGER = logging.getLogger(__package__)\n",
    "\n",
    "\n",
    "def main():\n",
    "    logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--dataset-dir\", required=True, help=\"Path to pre-processed dataset directory\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--checkpoint-epochs\",\n",
    "        type=int,\n",
    "        help=\"Save checkpoint every N epochs (default: 1)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--quality\",\n",
    "        default=\"medium\",\n",
    "        choices=(\"x-low\", \"medium\", \"high\"),\n",
    "        help=\"Quality/size of model (default: medium)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--resume_from_single_speaker_checkpoint\",\n",
    "        help=\"For multi-speaker models only. Converts a single-speaker checkpoint to multi-speaker and resumes training\",\n",
    "    )\n",
    "    \n",
    "    # Manually add PL 2.x arguments that we use\n",
    "    parser.add_argument(\"--max_epochs\", type=int, default=1000)\n",
    "    parser.add_argument(\"--accelerator\", default=\"auto\")\n",
    "    parser.add_argument(\"--devices\", default=\"auto\")\n",
    "    parser.add_argument(\"--precision\", default=\"32-true\")\n",
    "    parser.add_argument(\"--default_root_dir\", type=str, default=None)\n",
    "    parser.add_argument(\"--resume_from_checkpoint\", type=str, default=None)\n",
    "\n",
    "    # Trainer.add_argparse_args(parser) # Removed in PL 2.0\n",
    "    VitsModel.add_model_specific_args(parser)\n",
    "    parser.add_argument(\"--seed\", type=int, default=1234)\n",
    "    args = parser.parse_args()\n",
    "    _LOGGER.debug(args)\n",
    "\n",
    "    args.dataset_dir = Path(args.dataset_dir)\n",
    "    if not args.default_root_dir:\n",
    "        args.default_root_dir = str(args.dataset_dir) # Must be string for Trainer explicitly\n",
    "    \n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    config_path = args.dataset_dir / \"config.json\"\n",
    "    dataset_path = args.dataset_dir / \"dataset.jsonl\"\n",
    "\n",
    "    with open(config_path, \"r\", encoding=\"utf-8\") as config_file:\n",
    "        config = json.load(config_file)\n",
    "        num_symbols = int(config[\"num_symbols\"])\n",
    "        num_speakers = int(config[\"num_speakers\"])\n",
    "        sample_rate = int(config[\"audio\"][\"sample_rate\"])\n",
    "\n",
    "\n",
    "    callbacks = []\n",
    "    if args.checkpoint_epochs is not None:\n",
    "        callbacks = [ModelCheckpoint(every_n_epochs=args.checkpoint_epochs)]\n",
    "        _LOGGER.debug(\n",
    "            \"Checkpoints will be saved every %s epoch(s)\", args.checkpoint_epochs\n",
    "        )\n",
    "\n",
    "    # Instantiate Trainer explicitly\n",
    "    trainer = Trainer(\n",
    "        max_epochs=args.max_epochs,\n",
    "        accelerator=args.accelerator,\n",
    "        devices=int(args.devices) if isinstance(args.devices, str) and args.devices.isdigit() else args.devices,\n",
    "        precision=args.precision,\n",
    "        default_root_dir=args.default_root_dir,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    dict_args = vars(args)\n",
    "    if args.quality == \"x-low\":\n",
    "        dict_args[\"hidden_channels\"] = 96\n",
    "        dict_args[\"inter_channels\"] = 96\n",
    "        dict_args[\"filter_channels\"] = 384\n",
    "    elif args.quality == \"high\":\n",
    "        dict_args[\"resblock\"] = \"1\"\n",
    "        dict_args[\"resblock_kernel_sizes\"] = (3, 7, 11)\n",
    "        dict_args[\"resblock_dilation_sizes\"] = (\n",
    "            (1, 3, 5),\n",
    "            (1, 3, 5),\n",
    "            (1, 3, 5),\n",
    "        )\n",
    "        dict_args[\"upsample_rates\"] = (8, 8, 2, 2)\n",
    "        dict_args[\"upsample_initial_channel\"] = 512\n",
    "        dict_args[\"upsample_kernel_sizes\"] = (16, 16, 4, 4)\n",
    "\n",
    "    model = VitsModel(\n",
    "        num_symbols=num_symbols,\n",
    "        num_speakers=num_speakers,\n",
    "        sample_rate=sample_rate,\n",
    "        dataset=[dataset_path],\n",
    "        **dict_args,\n",
    "    )\n",
    "\n",
    "    if args.resume_from_single_speaker_checkpoint:\n",
    "        assert (\n",
    "            num_speakers > 1\n",
    "        ), \"--resume_from_single_speaker_checkpoint is only for multi-speaker models. Use --resume_from_checkpoint for single-speaker models.\"\n",
    "\n",
    "        # Load single-speaker checkpoint\n",
    "        _LOGGER.debug(\n",
    "            \"Resuming from single-speaker checkpoint: %s\",\n",
    "            args.resume_from_single_speaker_checkpoint,\n",
    "        )\n",
    "        model_single = VitsModel.load_from_checkpoint(\n",
    "            args.resume_from_single_speaker_checkpoint,\n",
    "            dataset=None,\n",
    "        )\n",
    "        g_dict = model_single.model_g.state_dict()\n",
    "        for key in list(g_dict.keys()):\n",
    "            # Remove keys that can't be copied over due to missing speaker embedding\n",
    "            if (\n",
    "                key.startswith(\"dec.cond\")\n",
    "                or key.startswith(\"dp.cond\")\n",
    "                or (\"enc.cond_layer\" in key)\n",
    "            ):\n",
    "                g_dict.pop(key, None)\n",
    "\n",
    "        # Copy over the multi-speaker model, excluding keys related to the\n",
    "        # speaker embedding (which is missing from the single-speaker model).\n",
    "        load_state_dict(model.model_g, g_dict)\n",
    "        load_state_dict(model.model_d, model_single.model_d.state_dict())\n",
    "        _LOGGER.info(\n",
    "            \"Successfully converted single-speaker checkpoint to multi-speaker\"\n",
    "        )\n",
    "\n",
    "    ckpt_path = args.resume_from_checkpoint\n",
    "    if args.resume_from_single_speaker_checkpoint:\n",
    "        ckpt_path = None # We manually loaded weights, start fresh\n",
    "\n",
    "    trainer.fit(model, ckpt_path=ckpt_path)\n",
    "\n",
    "\n",
    "def load_state_dict(model, saved_state_dict):\n",
    "    state_dict = model.state_dict()\n",
    "    new_state_dict = {}\n",
    "\n",
    "    for k, v in state_dict.items():\n",
    "        if k in saved_state_dict:\n",
    "            # Use saved value\n",
    "            new_state_dict[k] = saved_state_dict[k]\n",
    "        else:\n",
    "            # Use initialized value\n",
    "            _LOGGER.debug(\"%s is not in the checkpoint\", k)\n",
    "            new_state_dict[k] = v\n",
    "\n",
    "    model.load_state_dict(new_state_dict)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\"\n",
    "\n",
    "# Write the new content to the file\n",
    "with open(file_path, \"w\") as f:\n",
    "    f.write(new_content)\n",
    "\n",
    "print(f\"✅ patched {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 🩹 Fix Lightning 2.x Optimization Loop\n",
    "import os\n",
    "\n",
    "# Define path to the file\n",
    "file_path = \"piper_repo/src/python/piper_train/vits/lightning.py\"\n",
    "\n",
    "# The CORRECTED content (Manual Optimization for PL 2.x)\n",
    "new_content = \"\"\"import logging\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch import autocast\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "from .commons import slice_segments\n",
    "from .dataset import Batch, PiperDataset, UtteranceCollate\n",
    "from .losses import discriminator_loss, feature_loss, generator_loss, kl_loss\n",
    "from .mel_processing import mel_spectrogram_torch, spec_to_mel_torch\n",
    "from .models import MultiPeriodDiscriminator, SynthesizerTrn\n",
    "\n",
    "_LOGGER = logging.getLogger(\"vits.lightning\")\n",
    "\n",
    "\n",
    "class VitsModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_symbols: int,\n",
    "        num_speakers: int,\n",
    "        # audio\n",
    "        resblock=\"2\",\n",
    "        resblock_kernel_sizes=(3, 5, 7),\n",
    "        resblock_dilation_sizes=(\n",
    "            (1, 2),\n",
    "            (2, 6),\n",
    "            (3, 12),\n",
    "        ),\n",
    "        upsample_rates=(8, 8, 4),\n",
    "        upsample_initial_channel=256,\n",
    "        upsample_kernel_sizes=(16, 16, 8),\n",
    "        # mel\n",
    "        filter_length: int = 1024,\n",
    "        hop_length: int = 256,\n",
    "        win_length: int = 1024,\n",
    "        mel_channels: int = 80,\n",
    "        sample_rate: int = 22050,\n",
    "        sample_bytes: int = 2,\n",
    "        channels: int = 1,\n",
    "        mel_fmin: float = 0.0,\n",
    "        mel_fmax: Optional[float] = None,\n",
    "        # model\n",
    "        inter_channels: int = 192,\n",
    "        hidden_channels: int = 192,\n",
    "        filter_channels: int = 768,\n",
    "        n_heads: int = 2,\n",
    "        n_layers: int = 6,\n",
    "        kernel_size: int = 3,\n",
    "        p_dropout: float = 0.1,\n",
    "        n_layers_q: int = 3,\n",
    "        use_spectral_norm: bool = False,\n",
    "        gin_channels: int = 0,\n",
    "        use_sdp: bool = True,\n",
    "        segment_size: int = 8192,\n",
    "        # training\n",
    "        dataset: Optional[List[Union[str, Path]]] = None,\n",
    "        learning_rate: float = 2e-4,\n",
    "        betas: Tuple[float, float] = (0.8, 0.99),\n",
    "        eps: float = 1e-9,\n",
    "        batch_size: int = 1,\n",
    "        lr_decay: float = 0.999875,\n",
    "        init_lr_ratio: float = 1.0,\n",
    "        warmup_epochs: int = 0,\n",
    "        c_mel: int = 45,\n",
    "        c_kl: float = 1.0,\n",
    "        grad_clip: Optional[float] = None,\n",
    "        num_workers: int = 1,\n",
    "        seed: int = 1234,\n",
    "        num_test_examples: int = 5,\n",
    "        validation_split: float = 0.1,\n",
    "        max_phoneme_ids: Optional[int] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # Lightning 2.x requires manual optimization for multiple optimizers\n",
    "        self.automatic_optimization = False\n",
    "\n",
    "        if (self.hparams.num_speakers > 1) and (self.hparams.gin_channels <= 0):\n",
    "            # Default gin_channels for multi-speaker model\n",
    "            self.hparams.gin_channels = 512\n",
    "\n",
    "        # Set up models\n",
    "        self.model_g = SynthesizerTrn(\n",
    "            n_vocab=self.hparams.num_symbols,\n",
    "            spec_channels=self.hparams.filter_length // 2 + 1,\n",
    "            segment_size=self.hparams.segment_size // self.hparams.hop_length,\n",
    "            inter_channels=self.hparams.inter_channels,\n",
    "            hidden_channels=self.hparams.hidden_channels,\n",
    "            filter_channels=self.hparams.filter_channels,\n",
    "            n_heads=self.hparams.n_heads,\n",
    "            n_layers=self.hparams.n_layers,\n",
    "            kernel_size=self.hparams.kernel_size,\n",
    "            p_dropout=self.hparams.p_dropout,\n",
    "            resblock=self.hparams.resblock,\n",
    "            resblock_kernel_sizes=self.hparams.resblock_kernel_sizes,\n",
    "            resblock_dilation_sizes=self.hparams.resblock_dilation_sizes,\n",
    "            upsample_rates=self.hparams.upsample_rates,\n",
    "            upsample_initial_channel=self.hparams.upsample_initial_channel,\n",
    "            upsample_kernel_sizes=self.hparams.upsample_kernel_sizes,\n",
    "            n_speakers=self.hparams.num_speakers,\n",
    "            gin_channels=self.hparams.gin_channels,\n",
    "            use_sdp=self.hparams.use_sdp,\n",
    "        )\n",
    "        self.model_d = MultiPeriodDiscriminator(\n",
    "            use_spectral_norm=self.hparams.use_spectral_norm\n",
    "        )\n",
    "\n",
    "        # Dataset splits\n",
    "        self._train_dataset: Optional[Dataset] = None\n",
    "        self._val_dataset: Optional[Dataset] = None\n",
    "        self._test_dataset: Optional[Dataset] = None\n",
    "        self._load_datasets(validation_split, num_test_examples, max_phoneme_ids)\n",
    "\n",
    "        # State kept between training optimizers\n",
    "        self._y = None\n",
    "        self._y_hat = None\n",
    "\n",
    "    def _load_datasets(\n",
    "        self,\n",
    "        validation_split: float,\n",
    "        num_test_examples: int,\n",
    "        max_phoneme_ids: Optional[int] = None,\n",
    "    ):\n",
    "        if self.hparams.dataset is None:\n",
    "            _LOGGER.debug(\"No dataset to load\")\n",
    "            return\n",
    "\n",
    "        full_dataset = PiperDataset(\n",
    "            self.hparams.dataset, max_phoneme_ids=max_phoneme_ids\n",
    "        )\n",
    "        valid_set_size = int(len(full_dataset) * validation_split)\n",
    "        train_set_size = len(full_dataset) - valid_set_size - num_test_examples\n",
    "\n",
    "        self._train_dataset, self._test_dataset, self._val_dataset = random_split(\n",
    "            full_dataset, [train_set_size, num_test_examples, valid_set_size]\n",
    "        )\n",
    "\n",
    "    def forward(self, text, text_lengths, scales, sid=None):\n",
    "        noise_scale = scales[0]\n",
    "        length_scale = scales[1]\n",
    "        noise_scale_w = scales[2]\n",
    "        audio, *_ = self.model_g.infer(\n",
    "            text,\n",
    "            text_lengths,\n",
    "            noise_scale=noise_scale,\n",
    "            length_scale=length_scale,\n",
    "            noise_scale_w=noise_scale_w,\n",
    "            sid=sid,\n",
    "        )\n",
    "\n",
    "        return audio\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self._train_dataset,\n",
    "            collate_fn=UtteranceCollate(\n",
    "                is_multispeaker=self.hparams.num_speakers > 1,\n",
    "                segment_size=self.hparams.segment_size,\n",
    "            ),\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self._val_dataset,\n",
    "            collate_fn=UtteranceCollate(\n",
    "                is_multispeaker=self.hparams.num_speakers > 1,\n",
    "                segment_size=self.hparams.segment_size,\n",
    "            ),\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self._test_dataset,\n",
    "            collate_fn=UtteranceCollate(\n",
    "                is_multispeaker=self.hparams.num_speakers > 1,\n",
    "                segment_size=self.hparams.segment_size,\n",
    "            ),\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch: Batch, batch_idx: int):\n",
    "        # Manual optimization for Lightning 2.x with multiple optimizers\n",
    "        opt_g, opt_d = self.optimizers()\n",
    "        \n",
    "        # Train Generator\n",
    "        loss_gen_all = self.training_step_g(batch)\n",
    "        opt_g.zero_grad()\n",
    "        self.manual_backward(loss_gen_all)\n",
    "        opt_g.step()\n",
    "        \n",
    "        # Train Discriminator\n",
    "        loss_disc_all = self.training_step_d(batch)\n",
    "        opt_d.zero_grad()\n",
    "        self.manual_backward(loss_disc_all)\n",
    "        opt_d.step()\n",
    "        \n",
    "        # Step learning rate schedulers\n",
    "        # Note: In manual optimization we should usually step schedulers manually too if they are step-based\n",
    "        # but exponential LR is epoch-based, so usually lightning handles it or we call it.\n",
    "        # Safe to simply step them here if configured as 'step' or let PL handle epoch end.\n",
    "        # For simplicity in this migration script, we explicitly step them.\n",
    "        sch_g, sch_d = self.lr_schedulers()\n",
    "        if self.trainer.is_last_batch:\n",
    "             sch_g.step()\n",
    "             sch_d.step()\n",
    "\n",
    "\n",
    "    def training_step_g(self, batch: Batch):\n",
    "        x, x_lengths, y, _, spec, spec_lengths, speaker_ids = (\n",
    "            batch.phoneme_ids,\n",
    "            batch.phoneme_lengths,\n",
    "            batch.audios,\n",
    "            batch.audio_lengths,\n",
    "            batch.spectrograms,\n",
    "            batch.spectrogram_lengths,\n",
    "            batch.speaker_ids if batch.speaker_ids is not None else None,\n",
    "        )\n",
    "        (\n",
    "            y_hat,\n",
    "            l_length,\n",
    "            _attn,\n",
    "            ids_slice,\n",
    "            _x_mask,\n",
    "            z_mask,\n",
    "            (_z, z_p, m_p, logs_p, _m_q, logs_q),\n",
    "        ) = self.model_g(x, x_lengths, spec, spec_lengths, speaker_ids)\n",
    "        self._y_hat = y_hat\n",
    "\n",
    "        mel = spec_to_mel_torch(\n",
    "            spec,\n",
    "            self.hparams.filter_length,\n",
    "            self.hparams.mel_channels,\n",
    "            self.hparams.sample_rate,\n",
    "            self.hparams.mel_fmin,\n",
    "            self.hparams.mel_fmax,\n",
    "        )\n",
    "        y_mel = slice_segments(\n",
    "            mel,\n",
    "            ids_slice,\n",
    "            self.hparams.segment_size // self.hparams.hop_length,\n",
    "        )\n",
    "        y_hat_mel = mel_spectrogram_torch(\n",
    "            y_hat.squeeze(1),\n",
    "            self.hparams.filter_length,\n",
    "            self.hparams.mel_channels,\n",
    "            self.hparams.sample_rate,\n",
    "            self.hparams.hop_length,\n",
    "            self.hparams.win_length,\n",
    "            self.hparams.mel_fmin,\n",
    "            self.hparams.mel_fmax,\n",
    "        )\n",
    "        y = slice_segments(\n",
    "            y,\n",
    "            ids_slice * self.hparams.hop_length,\n",
    "            self.hparams.segment_size,\n",
    "        )  # slice\n",
    "\n",
    "        # Save for training_step_d\n",
    "        self._y = y\n",
    "\n",
    "        _y_d_hat_r, y_d_hat_g, fmap_r, fmap_g = self.model_d(y, y_hat)\n",
    "\n",
    "        with autocast(self.device.type, enabled=False):\n",
    "            # Generator loss\n",
    "            loss_dur = torch.sum(l_length.float())\n",
    "            loss_mel = F.l1_loss(y_mel, y_hat_mel) * self.hparams.c_mel\n",
    "            loss_kl = kl_loss(z_p, logs_q, m_p, logs_p, z_mask) * self.hparams.c_kl\n",
    "\n",
    "            loss_fm = feature_loss(fmap_r, fmap_g)\n",
    "            loss_gen, _losses_gen = generator_loss(y_d_hat_g)\n",
    "            loss_gen_all = loss_gen + loss_fm + loss_mel + loss_dur + loss_kl\n",
    "\n",
    "            self.log(\"loss_gen_all\", loss_gen_all, prog_bar=True)\n",
    "\n",
    "            return loss_gen_all\n",
    "\n",
    "    def training_step_d(self, batch: Batch):\n",
    "        # From training_step_g\n",
    "        y = self._y\n",
    "        y_hat = self._y_hat\n",
    "        y_d_hat_r, y_d_hat_g, _, _ = self.model_d(y, y_hat.detach())\n",
    "\n",
    "        with autocast(self.device.type, enabled=False):\n",
    "            # Discriminator\n",
    "            loss_disc, _losses_disc_r, _losses_disc_g = discriminator_loss(\n",
    "                y_d_hat_r, y_d_hat_g\n",
    "            )\n",
    "            loss_disc_all = loss_disc\n",
    "\n",
    "            self.log(\"loss_disc_all\", loss_disc_all, prog_bar=True)\n",
    "\n",
    "            return loss_disc_all\n",
    "\n",
    "    def validation_step(self, batch: Batch, batch_idx: int):\n",
    "        val_loss = self.training_step_g(batch) + self.training_step_d(batch)\n",
    "        self.log(\"val_loss\", val_loss, prog_bar=True)\n",
    "\n",
    "        # Generate audio examples\n",
    "        for utt_idx, test_utt in enumerate(self._test_dataset):\n",
    "            text = test_utt.phoneme_ids.unsqueeze(0).to(self.device)\n",
    "            text_lengths = torch.LongTensor([len(test_utt.phoneme_ids)]).to(self.device)\n",
    "            scales = [0.667, 1.0, 0.8]\n",
    "            sid = (\n",
    "                test_utt.speaker_id.to(self.device)\n",
    "                if test_utt.speaker_id is not None\n",
    "                else None\n",
    "            )\n",
    "            test_audio = self(text, text_lengths, scales, sid=sid).detach()\n",
    "\n",
    "            # Scale to make louder in [-1, 1]\n",
    "            test_audio = test_audio * (1.0 / max(0.01, abs(test_audio.max())))\n",
    "\n",
    "            tag = test_utt.text or str(utt_idx)\n",
    "            self.logger.experiment.add_audio(\n",
    "                tag, test_audio, sample_rate=self.hparams.sample_rate\n",
    "            )\n",
    "\n",
    "        return val_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizers = [\n",
    "            torch.optim.AdamW(\n",
    "                self.model_g.parameters(),\n",
    "                lr=self.hparams.learning_rate,\n",
    "                betas=self.hparams.betas,\n",
    "                eps=self.hparams.eps,\n",
    "            ),\n",
    "            torch.optim.AdamW(\n",
    "                self.model_d.parameters(),\n",
    "                lr=self.hparams.learning_rate,\n",
    "                betas=self.hparams.betas,\n",
    "                eps=self.hparams.eps,\n",
    "            ),\n",
    "        ]\n",
    "        schedulers = [\n",
    "            torch.optim.lr_scheduler.ExponentialLR(\n",
    "                optimizers[0], gamma=self.hparams.lr_decay\n",
    "            ),\n",
    "            torch.optim.lr_scheduler.ExponentialLR(\n",
    "                optimizers[1], gamma=self.hparams.lr_decay\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        return [\n",
    "            {\"optimizer\": optimizers[0], \"lr_scheduler\": schedulers[0]},\n",
    "            {\"optimizer\": optimizers[1], \"lr_scheduler\": schedulers[1]},\n",
    "        ]\n",
    "\n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser):\n",
    "        parser = parent_parser.add_argument_group(\"VitsModel\")\n",
    "        parser.add_argument(\"--batch-size\", type=int, required=True)\n",
    "        parser.add_argument(\"--validation-split\", type=float, default=0.1)\n",
    "        parser.add_argument(\"--num-test-examples\", type=int, default=5)\n",
    "        parser.add_argument(\n",
    "            \"--max-phoneme-ids\",\n",
    "            type=int,\n",
    "            help=\"Exclude utterances with phoneme id lists longer than this\",\n",
    "        )\n",
    "        #\n",
    "        parser.add_argument(\"--hidden-channels\", type=int, default=192)\n",
    "        parser.add_argument(\"--inter-channels\", type=int, default=192)\n",
    "        parser.add_argument(\"--filter-channels\", type=int, default=768)\n",
    "        parser.add_argument(\"--n-layers\", type=int, default=6)\n",
    "        parser.add_argument(\"--n-heads\", type=int, default=2)\n",
    "        #\n",
    "        return parent_parser\n",
    "\"\"\"\n",
    "\n",
    "# Write the new content to the file\n",
    "with open(file_path, \"w\") as f:\n",
    "    f.write(new_content)\n",
    "\n",
    "print(f\"✅ patched {file_path}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
