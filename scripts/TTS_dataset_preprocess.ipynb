{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abc01a55",
   "metadata": {},
   "source": [
    "### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UPN9ss5mOaY0"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c68027",
   "metadata": {},
   "source": [
    "### Dataset Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: File not found at ../hindi_female_english.zip\n",
      "Current working directory: /Users/rutwik/piper-model-training/scripts\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "# Unzip the main dataset file from the parent directory\n",
    "zip_path = '../hindi_female_english.zip'\n",
    "output_dir = 'dataset'\n",
    "if os.path.exists(zip_path):\n",
    "    print(f\"Found zip file at: {zip_path}\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(output_dir)\n",
    "        print(f\"Successfully extracted to '{output_dir}/'\")\n",
    "else:\n",
    "    print(f\"Error: File not found at {zip_path}\")\n",
    "    print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa159e4",
   "metadata": {},
   "source": [
    "### Some Analysis of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "bKwYT_ZgYYcV"
   },
   "outputs": [],
   "source": [
    "path_to_file = 'dataset/english/txt.done.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UFu7680EYYkd"
   },
   "outputs": [],
   "source": [
    "text = open(path_to_file, 'r',encoding='utf-8',\n",
    "                 errors='ignore').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EwiIy8uAg5uW",
    "outputId": "08a878ad-b45c-431d-992f-2b9a7515533c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( train_hindifullfemale_00001 \" Author of the danger trail, Philip Steels, etc. \" )\n",
      "( train_hindifullfemale_00002 \" Not at this particular case, Tom, apologized Whittemore. \" )\n",
      "( train_hindifullfemale_00003 \" For the twentieth time that evening the two men shook hands. \" )\n",
      "( train_hindifullfemale_00004 \" Lord, but I'm glad to see you again, Phil. \" )\n",
      "( train_hindifullfemale_00005 \" Will we ever forget it. \" )\n",
      "( train_hindifullfemale_00006 \" God bless 'em, I hope I'll go on seeing them forever. \" )\n",
      "( train_hindifullfemale_00007 \" And you always want to see it in the superlative degree. \" )\n",
      "( train_hindifullfemale_00008 \" Gad, your letter came just in time. \" )\n",
      "( train_hindifullfemale_00009 \" He turned sharply, and faced Gregson across the table. \" )\n",
      "( train_hindifullfemale_00010 \" I'm playing a single hand in what looks like a losing game. \" )\n",
      "( train_hindifullfemale_00011 \" If I ever needed a fighter in my life I need one now. \" )\n",
      "( train_hindifullfemale_00012 \" Gregson shoved back his\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qXwFnClVg9Tc",
    "outputId": "98761e2b-42cd-4a64-8143-49e3797beab1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'Z', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'â€“']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print(vocab)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0DqbY2zdhCEn",
    "outputId": "d00cd80a-bd91-4e46-bb88-e6379d9a6bbb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2921"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_ind = {u:i for i, u in enumerate(vocab)}\n",
    "ind_to_char = np.array(vocab)\n",
    "encoded_text = np.array([char_to_ind[c] for c in text])\n",
    "seq_len = 250\n",
    "total_num_seq = len(text)//(seq_len+1)\n",
    "total_num_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "EE41QOwihHeS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-14 16:27:20.233018: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/rutwik/miniconda3/envs/voice_training/lib/python3.11/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)\n",
    "\n",
    "sequences = char_dataset.batch(seq_len+1, drop_remainder=True)\n",
    "\n",
    "def create_seq_targets(seq):\n",
    "    input_txt = seq[:-1]\n",
    "    target_txt = seq[1:]\n",
    "    return input_txt, target_txt\n",
    "\n",
    "dataset = sequences.map(create_seq_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7a0a8c",
   "metadata": {},
   "source": [
    "### Forming the metadata.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "h5BgyakeNkRI",
    "outputId": "ad744268-d771-4188-c418-22824adac749"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6541, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_hindifullfemale_00001</td>\n",
       "      <td>Author of the danger trail, Philip Steels, etc.</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_hindifullfemale_00002</td>\n",
       "      <td>Not at this particular case, Tom, apologized W...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_hindifullfemale_00003</td>\n",
       "      <td>For the twentieth time that evening the two me...</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_hindifullfemale_00004</td>\n",
       "      <td>Lord, but I'm glad to see you again, Phil.</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_hindifullfemale_00005</td>\n",
       "      <td>Will we ever forget it.</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0  \\\n",
       "0  train_hindifullfemale_00001   \n",
       "1  train_hindifullfemale_00002   \n",
       "2  train_hindifullfemale_00003   \n",
       "3  train_hindifullfemale_00004   \n",
       "4  train_hindifullfemale_00005   \n",
       "\n",
       "                                                   1       2  \n",
       "0    Author of the danger trail, Philip Steels, etc.  female  \n",
       "1  Not at this particular case, Tom, apologized W...  female  \n",
       "2  For the twentieth time that evening the two me...  female  \n",
       "3         Lord, but I'm glad to see you again, Phil.  female  \n",
       "4                            Will we ever forget it.  female  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and clean\n",
    "metadata_female_fp = \"dataset/english/txt.done.data\"\n",
    "\n",
    "# Read file split by double quotes (to separate filename and transcript)\n",
    "metadata_female = pd.read_csv(metadata_female_fp, sep='\"', usecols=[0, 1], header=None)\n",
    "\n",
    "# Clean filename: remove leading '(' and whitespace\n",
    "metadata_female[0] = metadata_female[0].str.replace(r'\\(', '', regex=True).str.strip()\n",
    "\n",
    "# Clean transcript: remove leading/trailing whitespace\n",
    "metadata_female[1] = metadata_female[1].str.strip()\n",
    "\n",
    "# Optional: add speaker info\n",
    "metadata_female[2] = 'female'\n",
    "\n",
    "# Show shape and preview\n",
    "print(metadata_female.shape)\n",
    "metadata_female.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcce591",
   "metadata": {},
   "source": [
    "### Bulding the metadata.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "pfBupyWZORfp"
   },
   "outputs": [],
   "source": [
    "metadata = metadata_female\n",
    "metadata.to_csv('dataset/english/metadata.csv', sep='|', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c6bc45",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VfTlT8gFhRTd",
    "outputId": "63a9c695-0812-4d20-88cb-a53f8b1049d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Path: /Users/rutwik/piper-model-training/scripts/dataset/english\n",
      "Piper Source Path: /Users/rutwik/piper-model-training/piper_repo/src/python\n",
      "INFO:preprocess:Single speaker dataset\n",
      "INFO:preprocess:Wrote dataset config\n",
      "INFO:preprocess:Processing 6541 utterance(s) with 12 worker(s)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 1. Define paths\n",
    "# Absolute path to your dataset folder (the one containing metadata.csv)\n",
    "dataset_path = os.path.abspath(\"dataset/english\")\n",
    "\n",
    "# Absolute path to the 'src/python' folder inside the cloned piper_repo\n",
    "# This is where the 'piper_train' python package lives\n",
    "piper_src_path = os.path.abspath(\"../piper_repo/src/python\")\n",
    "\n",
    "print(f\"Dataset Path: {dataset_path}\")\n",
    "print(f\"Piper Source Path: {piper_src_path}\")\n",
    "\n",
    "# 2. Run the command with PYTHONPATH set\n",
    "# This tells Python: \"Look in 'piper_src_path' when I ask for 'piper_train'\"\n",
    "!PYTHONPATH=\"{piper_src_path}\" python3 -m piper_train.preprocess \\\n",
    "  --language en \\\n",
    "  --input-dir \"{dataset_path}\" \\\n",
    "  --output-dir training_dir \\\n",
    "  --dataset-format ljspeech \\\n",
    "  --single-speaker \\\n",
    "  --sample-rate 22050"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd29f8b",
   "metadata": {},
   "source": [
    "### Building the monotonic align "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created temp_build\n",
      "Copied core.pyx\n",
      "Copied setup.py\n",
      "/Users/rutwik/piper-model-training/scripts/temp_build\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# 1. Define paths\n",
    "# Points to: /Users/rutwik/piper-model-training/piper_repo/src/python\n",
    "piper_src_path = os.path.abspath(\"../piper_repo/src/python\")\n",
    "\n",
    "# Source files we need to compile\n",
    "monotonic_align_src = os.path.join(piper_src_path, \"piper_train/vits/monotonic_align\")\n",
    "temp_build_dir = \"temp_build\"\n",
    "\n",
    "# 2. Create temp directory\n",
    "os.makedirs(temp_build_dir, exist_ok=True)\n",
    "print(f\"Created {temp_build_dir}\")\n",
    "\n",
    "# 3. Copy necessary files (core.pyx and setup.py)\n",
    "for filename in [\"core.pyx\", \"setup.py\"]:\n",
    "    src_file = os.path.join(monotonic_align_src, filename)\n",
    "    dst_file = os.path.join(temp_build_dir, filename)\n",
    "    if os.path.exists(src_file):\n",
    "        shutil.copy(src_file, dst_file)\n",
    "        print(f\"Copied {filename}\")\n",
    "    else:\n",
    "        print(f\"Error: Could not find {filename} at {src_file}\")\n",
    "\n",
    "# 4. Move into the build directory\n",
    "%cd {temp_build_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d08434b",
   "metadata": {},
   "source": [
    "### Copying the monotonic align file core.so "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "guWq3XUgzeQ_",
    "outputId": "8bcd42b6-6e56-4c5e-9d8b-e98b869ee06f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling /Users/rutwik/piper-model-training/scripts/temp_build/core.pyx because it changed.\n",
      "[1/1] Cythonizing /Users/rutwik/piper-model-training/scripts/temp_build/core.pyx\n",
      "/Users/rutwik/miniconda3/envs/voice_training/lib/python3.11/site-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /Users/rutwik/piper-model-training/scripts/temp_build/core.pyx\n",
      "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "ld: warning: duplicate -rpath '/Users/rutwik/miniconda3/envs/voice_training/lib' ignored\n",
      "Copying core.cpython-311-darwin.so to /Users/rutwik/piper-model-training/piper_repo/src/python/piper_train/vits/monotonic_align...\n",
      "Success: Monotonic alignment module built and installed.\n"
     ]
    }
   ],
   "source": [
    "!python3 setup.py build_ext --inplace\n",
    "\n",
    "# Copy the compiled .so file back to the SOURCE location in piper_repo\n",
    "# This is crucial so the training script can find it later\n",
    "import shutil\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Find the compiled file (e.g., core.cpython-311-darwin.so)\n",
    "compiled_files = glob.glob(\"core*.so\")\n",
    "\n",
    "if compiled_files:\n",
    "    src_so = compiled_files[0]\n",
    "    # Destination: piper_train/vits/monotonic_align/ inside your repo\n",
    "    dest_dir = os.path.join(piper_src_path, \"piper_train/vits/monotonic_align\")\n",
    "    \n",
    "    print(f\"Copying {src_so} to {dest_dir}...\")\n",
    "    shutil.copy(src_so, dest_dir)\n",
    "    print(\"Success: Monotonic alignment module built and installed.\")\n",
    "else:\n",
    "    print(\"Error: Build failed, no .so file found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a01f9b",
   "metadata": {},
   "source": [
    "### Checking if the core.so is formed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6g5YbZL60jLg",
    "outputId": "e7006153-4484-460b-8a5c-10558c676607"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing contents of: /Users/rutwik/piper-model-training/piper_repo/src/python/piper_train/vits/monotonic_align\n",
      "Makefile\n",
      "__init__.py\n",
      "core.c\n",
      "setup.py\n",
      "core.cpython-311-darwin.so\n",
      "core.pyx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the correct path to the monotonic_align directory\n",
    "# Assuming 'piper_src_path' is still defined from previous cells as ../piper_repo/src/python\n",
    "piper_src_path = os.path.abspath(\"../../piper_repo/src/python\") # Adjusting for being inside temp_build\n",
    "monotonic_align_dir = os.path.join(piper_src_path, \"piper_train/vits/monotonic_align\")\n",
    "\n",
    "print(f\"Listing contents of: {monotonic_align_dir}\")\n",
    "\n",
    "if os.path.exists(monotonic_align_dir):\n",
    "    files = os.listdir(monotonic_align_dir)\n",
    "    for f in files:\n",
    "        print(f)\n",
    "else:\n",
    "    print(\"Directory not found. Please check the path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315e9a65",
   "metadata": {},
   "source": [
    "### Checking if the CSV file is Correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0mGcSQCeEAxz",
    "outputId": "d481daad-0c28-4e82-bea9-dc21bf64e936"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rutwik/piper-model-training/scripts\n",
      "Reading: /Users/rutwik/piper-model-training/scripts/dataset/english/metadata.csv\n",
      "train_hindifullfemale_00001|Author of the danger trail, Philip Steels, etc.|female\n",
      "train_hindifullfemale_00002|Not at this particular case, Tom, apologized Whittemore.|female\n",
      "train_hindifullfemale_00003|For the twentieth time that evening the two men shook hands.|female\n",
      "train_hindifullfemale_00004|Lord, but I'm glad to see you again, Phil.|female\n",
      "train_hindifullfemale_00005|Will we ever forget it.|female\n"
     ]
    }
   ],
   "source": [
    "# 1. Switch back to the main scripts directory\n",
    "%cd ..\n",
    "\n",
    "import os\n",
    "\n",
    "# 2. Define the correct path relative to 'scripts'\n",
    "dataset_csv_path = os.path.abspath(\"dataset/english/metadata.csv\")\n",
    "\n",
    "print(f\"Reading: {dataset_csv_path}\")\n",
    "\n",
    "# 3. Read and print the file\n",
    "if os.path.exists(dataset_csv_path):\n",
    "    with open(dataset_csv_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            print(line.strip())\n",
    "            if i == 4:  # Show only first 5 lines\n",
    "                break\n",
    "else:\n",
    "    print(f\"Error: File not found at {dataset_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "voice_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
